"""
Detector de Comandos Unificado - Roxy Megurdy (FINAL SIMPLIFICADO + GROK)
===========================================
Sistema inteligente que delega todas las decisiones complejas a Ollama/Llama.
Ahora con capacidad de consultar Grok para resolver comandos complejos.
Solo maneja casos ultra-obvios como fallback.
"""

import os
import json
import time
import subprocess
import webbrowser
import re
import glob
import psutil
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass

try:
    import ollama
    OLLAMA_AVAILABLE = True
except ImportError:
    OLLAMA_AVAILABLE = False
    print("丘멆잺 Ollama no disponible - funcionalidad limitada")

try:
    from advanced_music_controller import AdvancedMusicController
    ADVANCED_MUSIC_AVAILABLE = True
except ImportError:
    ADVANCED_MUSIC_AVAILABLE = False
    print("丘멆잺 Controlador avanzado de m칰sica no disponible")

try:
    from memory_bridge import MemoryBridge
    MEMORY_BRIDGE_AVAILABLE = True
except ImportError:
    MEMORY_BRIDGE_AVAILABLE = False
    print("丘멆잺 MemoryBridge no disponible")

try:
    from conversation_memory import ConversationMemory
    CONVERSATION_MEMORY_AVAILABLE = True
except ImportError:
    CONVERSATION_MEMORY_AVAILABLE = False
    print("丘멆잺 ConversationMemory no disponible")

try:
    from spotify_controller_unified import SpotifyControllerUnified
    SPOTIFY_API_AVAILABLE = True
except ImportError:
    SPOTIFY_API_AVAILABLE = False
    print("丘멆잺 Controlador de Spotify Unificado no disponible")

try:
    from intelligent_music_selector import IntelligentMusicSelector
    INTELLIGENT_SELECTOR_AVAILABLE = True
except ImportError:
    INTELLIGENT_SELECTOR_AVAILABLE = False
    print("丘멆잺 Selector Inteligente de M칰sica no disponible")

try:
    from automatic_command_corrector import AutomaticCommandCorrector
    AUTOMATIC_CORRECTOR_AVAILABLE = True
except ImportError:
    AUTOMATIC_CORRECTOR_AVAILABLE = False
    print("丘멆잺 Corrector Autom치tico de Comandos no disponible")

@dataclass
class CommandResult:
    """Resultado del an치lisis de comando"""
    is_command: bool
    command_type: str  # 'app', 'music', 'content', 'conversation'
    action: str  # 'open_app', 'play_music', 'search_content', 'chat'
    target: Optional[str]  # nombre de app/canci칩n/serie/etc
    confidence: float
    natural_response: Optional[str]
    execution_data: Dict[str, Any]  # datos espec칤ficos para ejecuci칩n
    needs_clarification: bool = False
    grok_query: Optional[str] = None
    grok_used: bool = False  # Nuevo: indica si se us칩 Grok para resolver
    original_query: Optional[str] = None  # Nuevo: guarda la consulta original

@dataclass
class ValidationResult:
    """Resultado de validaci칩n pre-ejecuci칩n"""
    should_execute: bool
    confidence_score: float  # 0.0 - 1.0
    warnings: List[str]
    blocking_issues: List[str]
    recommendations: List[str]
    execution_delay: int = 0  # segundos a esperar antes de ejecutar
    
@dataclass
class SystemState:
    """Estado actual del sistema"""
    running_processes: List[str]
    cpu_usage: float
    memory_usage: float
    active_window: Optional[str]
    user_idle_time: float  # segundos desde 칰ltima actividad
    current_time: datetime
    
@dataclass
class ValidationContext:
    """Contexto para validaci칩n"""
    user_input: str
    command_result: CommandResult
    system_state: SystemState
    recent_commands: List[Dict[str, Any]]
    user_preferences: Dict[str, Any]

@dataclass
class FailureRecord:
    """Registro de fallo en el sistema"""
    user_input: str
    intended_action: str
    actual_result: str
    command_type: str
    confidence: float
    timestamp: datetime
    error_category: str  # 'parsing', 'execution', 'validation', 'misinterpretation'
    context: Dict[str, Any]

@dataclass
class AmbiguitySignal:
    """Se침al de ambig칲edad detectada"""
    signal_type: str  # 'multiple_interpretations', 'incomplete_command', 'missing_context', 'history_conflict', 'low_confidence', 'conflicting_targets'
    severity: float  # 0.0 - 1.0
    description: str
    suggested_clarifications: List[str]
    context_data: Dict[str, Any]
    
@dataclass 
class AmbiguityAnalysis:
    """An치lisis completo de ambig칲edad"""
    has_ambiguity: bool
    ambiguity_score: float  # 0.0 - 1.0
    signals: List[AmbiguitySignal]
    primary_interpretations: List[Dict[str, Any]]
    confidence_factors: Dict[str, float]
    recommended_action: str  # 'execute', 'clarify', 'suggest_alternatives'
    clarification_questions: List[str]

class LearningSystem:
    """
    Sistema de aprendizaje autom치tico por errores
    Mejora el sistema_prompt y la detecci칩n de comandos bas치ndose en fallos previos
    """
    
    def __init__(self, learning_file: str = "learning_data.json"):
        self.learning_file = learning_file
        self.failure_patterns: List[FailureRecord] = []
        self.success_patterns: List[Dict[str, Any]] = []
        self.improvement_history: List[Dict[str, Any]] = []
        self.load_learning_data()
        
    def load_learning_data(self):
        """Cargar datos de aprendizaje desde archivo"""
        try:
            if os.path.exists(self.learning_file):
                with open(self.learning_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                # Cargar registros de fallos
                for failure_data in data.get('failures', []):
                    failure = FailureRecord(
                        user_input=failure_data['user_input'],
                        intended_action=failure_data['intended_action'],
                        actual_result=failure_data['actual_result'],
                        command_type=failure_data['command_type'],
                        confidence=failure_data['confidence'],
                        timestamp=datetime.fromisoformat(failure_data['timestamp']),
                        error_category=failure_data['error_category'],
                        context=failure_data['context']
                    )
                    self.failure_patterns.append(failure)
                    
                self.success_patterns = data.get('successes', [])
                self.improvement_history = data.get('improvements', [])
                
                print(f"游닄 Datos de aprendizaje cargados: {len(self.failure_patterns)} fallos, {len(self.success_patterns)} 칠xitos")
        except Exception as e:
            print(f"丘멆잺 Error cargando datos de aprendizaje: {e}")
    
    def save_learning_data(self):
        """Guardar datos de aprendizaje en archivo"""
        try:
            data = {
                'failures': [
                    {
                        'user_input': f.user_input,
                        'intended_action': f.intended_action,
                        'actual_result': f.actual_result,
                        'command_type': f.command_type,
                        'confidence': f.confidence,
                        'timestamp': f.timestamp.isoformat(),
                        'error_category': f.error_category,
                        'context': f.context
                    } for f in self.failure_patterns
                ],
                'successes': self.success_patterns,
                'improvements': self.improvement_history
            }
            
            with open(self.learning_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            print(f"丘멆잺 Error guardando datos de aprendizaje: {e}")
    
    def record_failure(self, user_input: str, intended_action: str, actual_result: str, 
                      command_type: str = "unknown", confidence: float = 0.0, 
                      error_category: str = "execution", context: Optional[Dict[str, Any]] = None):
        """Registrar un fallo en el sistema"""
        failure = FailureRecord(
            user_input=user_input,
            intended_action=intended_action,
            actual_result=actual_result,
            command_type=command_type,
            confidence=confidence,
            timestamp=datetime.now(),
            error_category=error_category,
            context=context or {}
        )
        
        self.failure_patterns.append(failure)
        print(f"游닇 Fallo registrado: {user_input} -> {error_category}")
        
        # Guardar autom치ticamente
        self.save_learning_data()
        
        # Analizar si necesitamos mejoras inmediatas
        if len(self.failure_patterns) % 5 == 0:  # Cada 5 fallos
            self._trigger_improvement_analysis()
    
    def record_success(self, user_input: str, command_result: CommandResult):
        """Registrar un 칠xito para aprender patrones positivos"""
        success_record = {
            'user_input': user_input,
            'command_type': command_result.command_type,
            'action': command_result.action,
            'target': command_result.target,
            'confidence': command_result.confidence,
            'timestamp': datetime.now().isoformat(),
            'grok_used': command_result.grok_used
        }
        
        self.success_patterns.append(success_record)
        
        # Mantener solo los 칰ltimos 100 칠xitos para no acumular demasiado
        if len(self.success_patterns) > 100:
            self.success_patterns = self.success_patterns[-100:]
            
        self.save_learning_data()
    
    def _trigger_improvement_analysis(self):
        """Analizar patrones de fallo y sugerir mejoras"""
        print("游댌 Analizando patrones de fallo para mejoras...")
        
        common_failures = self._analyze_failure_patterns()
        if common_failures:
            improvements = self._generate_improvements(common_failures)
            if improvements:
                print(f"游눠 {len(improvements)} mejoras identificadas")
                return improvements
        
        return []
    
    def _analyze_failure_patterns(self) -> Dict[str, Any]:
        """Analizar patrones comunes en los fallos"""
        if not self.failure_patterns:
            return {}
        
        # An치lisis por categor칤a de error
        error_categories = {}
        command_types = {}
        confidence_issues = []
        recent_failures = []
        
        # Filtrar fallos recientes (칰ltimos 7 d칤as)
        week_ago = datetime.now() - timedelta(days=7)
        recent_failures = [f for f in self.failure_patterns if f.timestamp > week_ago]
        
        for failure in recent_failures:
            # Contar por categor칤a de error
            if failure.error_category not in error_categories:
                error_categories[failure.error_category] = []
            error_categories[failure.error_category].append(failure)
            
            # Contar por tipo de comando
            if failure.command_type not in command_types:
                command_types[failure.command_type] = []
            command_types[failure.command_type].append(failure)
            
            # Detectar problemas de confianza
            if failure.confidence < 0.7:
                confidence_issues.append(failure)
        
        return {
            'error_categories': error_categories,
            'command_types': command_types,
            'confidence_issues': confidence_issues,
            'recent_count': len(recent_failures),
            'total_count': len(self.failure_patterns)
        }
    
    def _generate_improvements(self, analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Generar mejoras basadas en el an치lisis de patrones"""
        improvements = []
        
        # Mejoras por categor칤a de error m치s com칰n
        error_categories = analysis.get('error_categories', {})
        if error_categories:
            most_common_error = max(error_categories.keys(), key=lambda k: len(error_categories[k]))
            error_count = len(error_categories[most_common_error])
            
            if error_count >= 3:  # Si hay 3+ fallos del mismo tipo
                improvement = self._create_improvement_for_error_category(
                    most_common_error, error_categories[most_common_error]
                )
                if improvement:
                    improvements.append(improvement)
        
        # Mejoras por tipo de comando problem치tico
        command_types = analysis.get('command_types', {})
        if command_types:
            for cmd_type, failures in command_types.items():
                if len(failures) >= 2:  # 2+ fallos del mismo tipo de comando
                    improvement = self._create_improvement_for_command_type(cmd_type, failures)
                    if improvement:
                        improvements.append(improvement)
        
        return improvements
    
    def _create_improvement_for_error_category(self, error_category: str, failures: List[FailureRecord]) -> Optional[Dict[str, Any]]:
        """Crear mejora espec칤fica para una categor칤a de error"""
        if error_category == "parsing":
            # Problemas de parsing - mejorar ejemplos en el prompt
            common_inputs = [f.user_input for f in failures]
            return {
                'type': 'prompt_enhancement',
                'category': error_category,
                'description': f'Mejorar parsing para inputs como: {", ".join(common_inputs[:3])}',
                'prompt_addition': f'\nEJEMPLOS PROBLEM츼TICOS A MEJORAR:\n' + 
                                 '\n'.join([f'- Input: "{f.user_input}" -> Debe ser: {f.intended_action}' 
                                           for f in failures[:3]])
            }
        
        elif error_category == "misinterpretation":
            # Problemas de interpretaci칩n - aclarar reglas
            return {
                'type': 'prompt_clarification',
                'category': error_category,
                'description': 'Aclarar reglas de interpretaci칩n',
                'prompt_addition': '\nREGLAS ADICIONALES:\n- Ser m치s espec칤fico en la interpretaci칩n de comandos ambiguos\n- Priorizar contexto del usuario'
            }
        
        elif error_category == "execution":
            # Problemas de ejecuci칩n - mejorar validaci칩n
            return {
                'type': 'validation_improvement',
                'category': error_category,
                'description': 'Mejorar validaci칩n pre-ejecuci칩n',
                'validation_rules': [f.actual_result for f in failures]
            }
        
        return None
    
    def _create_improvement_for_command_type(self, command_type: str, failures: List[FailureRecord]) -> Optional[Dict[str, Any]]:
        """Crear mejora espec칤fica para un tipo de comando problem치tico"""
        common_patterns = {}
        for failure in failures:
            pattern = failure.user_input.lower()
            if pattern not in common_patterns:
                common_patterns[pattern] = []
            common_patterns[pattern].append(failure)
        
        if common_patterns:
            most_common = max(common_patterns.keys(), key=lambda k: len(common_patterns[k]))
            return {
                'type': 'command_type_improvement',
                'category': command_type,
                'description': f'Mejorar detecci칩n para comandos tipo "{command_type}"',
                'prompt_addition': f'\nMEJORA PARA {command_type.upper()}:\n- Patr칩n problem치tico: "{most_common}"\n- Debe detectarse como: {command_type}'
            }
        
        return None
    
    def get_prompt_improvements(self) -> str:
        """Obtener mejoras para el system_prompt basadas en aprendizaje"""
        if not self.failure_patterns:
            return ""
        
        analysis = self._analyze_failure_patterns()
        improvements = self._generate_improvements(analysis)
        
        if not improvements:
            return ""
        
        prompt_additions = []
        for improvement in improvements:
            if improvement.get('type') in ['prompt_enhancement', 'prompt_clarification']:
                prompt_additions.append(improvement.get('prompt_addition', ''))
        
        if prompt_additions:
            return "\n\n--- MEJORAS BASADAS EN APRENDIZAJE ---" + "".join(prompt_additions)
        
        return ""
    
    def apply_improvements_to_prompt(self, original_prompt: str) -> str:
        """Aplicar mejoras autom치ticamente al prompt"""
        improvements = self.get_prompt_improvements()
        if improvements:
            improved_prompt = original_prompt + improvements
            
            # Registrar la mejora
            self.improvement_history.append({
                'timestamp': datetime.now().isoformat(),
                'type': 'automatic_prompt_improvement',
                'original_length': len(original_prompt),
                'improved_length': len(improved_prompt),
                'improvements_applied': len(self.failure_patterns)
            })
            
            self.save_learning_data()
            print(f"游 Prompt mejorado autom치ticamente basado en {len(self.failure_patterns)} fallos registrados")
            return improved_prompt
        
        return original_prompt

class AmbiguityDetector:
    """
    游댌 DETECTOR DE AMBIG칖EDAD AVANZADO
    ====================================
    
    Sistema inteligente que detecta m칰ltiples tipos de ambig칲edad en comandos
    y proporciona an치lisis detallado con sugerencias de clarificaci칩n.
    
    Caracter칤sticas:
    - Detecci칩n de m칰ltiples interpretaciones posibles
    - An치lisis de contexto hist칩rico y conflictos
    - Sistema de puntuaci칩n de confianza
    - Generaci칩n de preguntas de clarificaci칩n inteligentes
    - Resoluci칩n autom치tica cuando es posible
    """
    
    def __init__(self, learning_system: Optional['LearningSystem'] = None):
        self.learning_system = learning_system
        self.confidence_threshold = 0.7  # Umbral m칤nimo de confianza
        self.ambiguity_threshold = 0.4   # Umbral para considerar ambiguo
        
        # Patrones de ambig칲edad conocidos
        self.ambiguous_patterns = {
            'multiple_apps': [
                r'\b(abre|abrir|ejecuta|ejecutar|lanza|lanzar)\s+(.+)',
                r'\b(reproduce|pon|play)\s+(.+)',
                r'\b(busca|buscar|encuentra|encontrar)\s+(.+)'
            ],
            'incomplete_commands': [
                r'^(abre|abrir)$',
                r'^(reproduce|pon|play)$',
                r'^(busca|buscar)$',
                r'^(cambia|cambiar)$'
            ],
            'vague_references': [
                r'\b(eso|esto|aquello|la anterior|el anterior)\b',
                r'\b(lo mismo|igual|similar)\b',
                r'\b(algo|alguna|alg칰n)\b'
            ],
            'conflicting_intents': [
                r'\b(abre|abrir).+(reproduce|pon|play)\b',
                r'\b(busca|buscar).+(abre|abrir)\b',
                r'\b(para|parar|pausa).+(reproduce|pon|play)\b'
            ]
        }
        
        # Contexto de aplicaciones conocidas
        self.known_apps = {
            'music': ['spotify', 'youtube music', 'vlc', 'windows media player', 'itunes'],
            'browsers': ['chrome', 'firefox', 'edge', 'opera', 'brave'],
            'media': ['netflix', 'disney+', 'prime video', 'youtube', 'twitch'],
            'games': ['steam', 'epic games', 'origin', 'uplay', 'battle.net'],
            'productivity': ['word', 'excel', 'powerpoint', 'notepad', 'calculator'],
            'communication': ['discord', 'teams', 'slack', 'whatsapp', 'telegram']
        }
        
        # Historial de comandos recientes para an치lisis de contexto
        self.recent_commands: List[Dict[str, Any]] = []
        
    def analyze_ambiguity(self, user_input: str, command_result: CommandResult, 
                         context: Optional[Dict[str, Any]] = None) -> AmbiguityAnalysis:
        """
        游댌 An치lisis completo de ambig칲edad en un comando
        
        Args:
            user_input: Entrada del usuario
            command_result: Resultado del an치lisis de comando
            context: Contexto adicional (historial, estado del sistema, etc.)
            
        Returns:
            AmbiguityAnalysis: An치lisis completo con se침ales y recomendaciones
        """
        print(f"游댌 Analizando ambig칲edad en: '{user_input}'")
        
        signals = []
        confidence_factors = {}
        
        # Realizar todas las verificaciones de ambig칲edad
        signals.extend(self._detect_multiple_interpretations(user_input, command_result, context))
        signals.extend(self._detect_incomplete_commands(user_input, command_result))
        signals.extend(self._detect_missing_context(user_input, command_result, context))
        signals.extend(self._detect_history_conflicts(user_input, command_result, context))
        signals.extend(self._detect_low_confidence(user_input, command_result))
        signals.extend(self._detect_conflicting_targets(user_input, command_result))
        signals.extend(self._detect_vague_references(user_input, command_result, context))
        
        # Calcular puntuaci칩n de ambig칲edad
        ambiguity_score = self._calculate_ambiguity_score(signals, command_result)
        
        # Determinar si hay ambig칲edad significativa
        has_ambiguity = ambiguity_score > self.ambiguity_threshold or len(signals) > 0
        
        # Generar interpretaciones alternativas
        primary_interpretations = self._generate_alternative_interpretations(
            user_input, command_result, signals, context
        )
        
        # Calcular factores de confianza
        confidence_factors = self._calculate_confidence_factors(
            user_input, command_result, signals, context
        )
        
        # Determinar acci칩n recomendada
        recommended_action = self._determine_recommended_action(
            ambiguity_score, command_result.confidence, signals
        )
        
        # Generar preguntas de clarificaci칩n
        clarification_questions = self._generate_clarification_questions(
            signals, user_input, primary_interpretations
        )
        
        analysis = AmbiguityAnalysis(
            has_ambiguity=has_ambiguity,
            ambiguity_score=ambiguity_score,
            signals=signals,
            primary_interpretations=primary_interpretations,
            confidence_factors=confidence_factors,
            recommended_action=recommended_action,
            clarification_questions=clarification_questions
        )
        
        print(f"游늵 An치lisis completado: ambig칲edad={has_ambiguity}, score={ambiguity_score:.2f}, acci칩n={recommended_action}")
        
        return analysis
    
    def _detect_multiple_interpretations(self, user_input: str, result: CommandResult, 
                                       context: Optional[Dict[str, Any]] = None) -> List[AmbiguitySignal]:
        """Detectar comandos que pueden tener m칰ltiples interpretaciones"""
        signals = []
        user_lower = user_input.lower()
        
        # Buscar t칠rminos que pueden referirse a m칰ltiples aplicaciones
        ambiguous_terms = {
            'm칰sica': ['spotify', 'youtube music', 'vlc', 'windows media player'],
            'video': ['youtube', 'netflix', 'vlc', 'windows media player'],
            'navegador': ['chrome', 'firefox', 'edge', 'opera'],
            'chat': ['discord', 'teams', 'whatsapp', 'telegram'],
            'juego': ['steam', 'epic games', 'origin', 'battle.net'],
            'editor': ['notepad', 'word', 'notepad++', 'visual studio code']
        }
        
        for term, apps in ambiguous_terms.items():
            if term in user_lower and not any(app in user_lower for app in apps):
                signals.append(AmbiguitySignal(
                    signal_type='multiple_interpretations',
                    severity=0.7,
                    description=f"El t칠rmino '{term}' puede referirse a m칰ltiples aplicaciones",
                    suggested_clarifications=[f"쯊e refieres a {app}?" for app in apps[:3]],
                    context_data={'term': term, 'possible_apps': apps}
                ))
        
        # Detectar nombres de aplicaciones similares
        if result.target:
            similar_apps = self._find_similar_app_names(result.target)
            if len(similar_apps) > 1:
                signals.append(AmbiguitySignal(
                    signal_type='multiple_interpretations',
                    severity=0.6,
                    description=f"Hay m칰ltiples aplicaciones similares a '{result.target}'",
                    suggested_clarifications=[f"쯊e refieres a {app}?" for app in similar_apps],
                    context_data={'target': result.target, 'similar_apps': similar_apps}
                ))
        
        return signals
    
    def _detect_incomplete_commands(self, user_input: str, result: CommandResult) -> List[AmbiguitySignal]:
        """Detectar comandos incompletos que necesitan m치s informaci칩n"""
        signals = []
        user_lower = user_input.lower().strip()
        
        # Comandos que requieren un target pero no lo tienen
        incomplete_patterns = [
            ('abre', 'abrir', '쯈u칠 aplicaci칩n quieres abrir?'),
            ('reproduce', 'reproducir', '쯈u칠 m칰sica o video quieres reproducir?'),
            ('busca', 'buscar', '쯈u칠 quieres buscar?'),
            ('cambia', 'cambiar', '쯈u칠 configuraci칩n quieres cambiar?'),
            ('para', 'parar', '쯈u칠 quieres parar?'),
            ('cierra', 'cerrar', '쯈u칠 aplicaci칩n quieres cerrar?')
        ]
        
        for pattern, action, question in incomplete_patterns:
            if user_lower == pattern and not result.target:
                signals.append(AmbiguitySignal(
                    signal_type='incomplete_command',
                    severity=0.8,
                    description=f"Comando '{action}' incompleto - falta especificar el objetivo",
                    suggested_clarifications=[question],
                    context_data={'action': action, 'pattern': pattern}
                ))
        
        # Comandos muy cortos (menos de 3 palabras) con baja confianza
        words = user_input.strip().split()
        if len(words) <= 2 and result.confidence < 0.6:
            signals.append(AmbiguitySignal(
                signal_type='incomplete_command',
                severity=0.6,
                description="Comando muy corto con baja confianza",
                suggested_clarifications=["쯇uedes ser m치s espec칤fico?", "쯈u칠 exactamente quieres hacer?"],
                context_data={'word_count': len(words), 'confidence': result.confidence}
            ))
        
        return signals
    
    def _detect_missing_context(self, user_input: str, result: CommandResult, 
                               context: Optional[Dict[str, Any]] = None) -> List[AmbiguitySignal]:
        """Detectar cuando falta contexto necesario para entender el comando"""
        signals = []
        
        # Referencias a "anterior", "칰ltimo", etc. sin historial
        vague_references = ['anterior', '칰ltimo', 'pasado', 'previo', 'ese', 'esa', 'eso']
        user_lower = user_input.lower()
        
        for ref in vague_references:
            if ref in user_lower:
                has_context = context and context.get('recent_commands')
                if not has_context or len((context or {}).get('recent_commands', [])) == 0:
                    signals.append(AmbiguitySignal(
                        signal_type='missing_context',
                        severity=0.7,
                        description=f"Referencia a '{ref}' sin contexto hist칩rico disponible",
                        suggested_clarifications=[
                            "쮸 qu칠 te refieres espec칤ficamente?",
                            "쯇uedes ser m치s espec칤fico sobre lo que mencionas?"
                        ],
                        context_data={'reference': ref, 'has_history': has_context}
                    ))
        
        # Comandos que dependen del estado actual sin informaci칩n del estado
        state_dependent = ['siguiente', 'anterior', 'contin칰a', 'reanuda', 'para']
        for dep in state_dependent:
            if dep in user_lower and result.action in ['control_music', 'control_media']:
                if not context or not context.get('current_media_state'):
                    signals.append(AmbiguitySignal(
                        signal_type='missing_context',
                        severity=0.6,
                        description=f"Comando '{dep}' requiere conocer el estado actual de reproducci칩n",
                        suggested_clarifications=[
                            "쮿ay algo reproduci칠ndose actualmente?",
                            "쮼n qu칠 aplicaci칩n quieres realizar esta acci칩n?"
                        ],
                        context_data={'dependency': dep, 'action': result.action}
                    ))
        
        return signals
    
    def _detect_history_conflicts(self, user_input: str, result: CommandResult, 
                                 context: Optional[Dict[str, Any]] = None) -> List[AmbiguitySignal]:
        """Detectar conflictos con comandos recientes o patrones hist칩ricos"""
        signals = []
        
        if not context or not context.get('recent_commands'):
            return signals
        
        recent_commands = context.get('recent_commands', [])
        
        # Detectar cambios r치pidos de intenci칩n
        if len(recent_commands) > 0:
            last_command = recent_commands[-1]
            last_action = last_command.get('action', '')
            current_action = result.action
            
            # Conflictos comunes
            conflicts = {
                ('open_app', 'search_music'): "Cambio r치pido de abrir app a reproducir m칰sica",
                ('search_music', 'open_app'): "Cambio r치pido de m칰sica a abrir aplicaci칩n",
                ('control_music', 'search_content'): "Cambio de control de m칰sica a b칰squeda de contenido"
            }
            
            conflict_key = (last_action, current_action)
            if conflict_key in conflicts:
                time_diff = datetime.now() - datetime.fromisoformat(last_command.get('timestamp', datetime.now().isoformat()))
                if time_diff.total_seconds() < 30:  # Menos de 30 segundos
                    signals.append(AmbiguitySignal(
                        signal_type='history_conflict',
                        severity=0.5,
                        description=conflicts[conflict_key],
                        suggested_clarifications=[
                            "쯈uieres cancelar la acci칩n anterior?",
                            "쮺onfirmas que quieres hacer esto ahora?"
                        ],
                        context_data={
                            'last_action': last_action,
                            'current_action': current_action,
                            'time_diff': time_diff.total_seconds()
                        }
                    ))
        
        return signals
    
    def _detect_low_confidence(self, user_input: str, result: CommandResult) -> List[AmbiguitySignal]:
        """Detectar baja confianza en el resultado del an치lisis"""
        signals = []
        
        if result.confidence < self.confidence_threshold:
            severity = 1.0 - result.confidence  # Mayor severidad = menor confianza
            
            signals.append(AmbiguitySignal(
                signal_type='low_confidence',
                severity=severity,
                description=f"Baja confianza en la interpretaci칩n ({result.confidence:.2f})",
                suggested_clarifications=[
                    "쮼s esto lo que quer칤as hacer?",
                    "쯇uedes reformular tu solicitud?",
                    "쯅ecesitas ayuda para especificar mejor lo que buscas?"
                ],
                context_data={
                    'confidence': result.confidence,
                    'threshold': self.confidence_threshold,
                    'interpretation': {
                        'action': result.action,
                        'target': result.target,
                        'command_type': result.command_type
                    }
                }
            ))
        
        return signals
    
    def _detect_conflicting_targets(self, user_input: str, result: CommandResult) -> List[AmbiguitySignal]:
        """Detectar m칰ltiples targets posibles en conflicto"""
        signals = []
        
        # Buscar m칰ltiples nombres de aplicaciones en el input
        found_apps = []
        user_lower = user_input.lower()
        
        for category, apps in self.known_apps.items():
            for app in apps:
                if app in user_lower:
                    found_apps.append((app, category))
        
        if len(found_apps) > 1:
            signals.append(AmbiguitySignal(
                signal_type='conflicting_targets',
                severity=0.6,
                description=f"M칰ltiples aplicaciones mencionadas: {', '.join([app for app, _ in found_apps])}",
                suggested_clarifications=[
                    f"쯊e refieres a {app}?" for app, _ in found_apps[:3]
                ],
                context_data={
                    'found_apps': found_apps,
                    'target': result.target
                }
            ))
        
        return signals
    
    def _detect_vague_references(self, user_input: str, result: CommandResult, 
                                context: Optional[Dict[str, Any]] = None) -> List[AmbiguitySignal]:
        """Detectar referencias vagas que necesitan clarificaci칩n"""
        signals = []
        
        vague_patterns = [
            (r'\b(algo|alguna|alg칰n)\s+de\s+', "Referencia vaga a contenido"),
            (r'\b(esa|ese|eso)\s+', "Pronombre demostrativo sin antecedente claro"),
            (r'\b(lo\s+de\s+|la\s+de\s+)', "Referencia indirecta"),
            (r'\b(como\s+antes|igual\s+que|similar\s+a)\b', "Comparaci칩n sin referente claro")
        ]
        
        for pattern, description in vague_patterns:
            match = re.search(pattern, user_input.lower())
            if match:
                signals.append(AmbiguitySignal(
                    signal_type='vague_references',
                    severity=0.6,
                    description=description,
                    suggested_clarifications=[
                        "쯇uedes ser m치s espec칤fico?",
                        "쮸 qu칠 te refieres exactamente?"
                    ],
                    context_data={'pattern': pattern, 'match': match.group()}
                ))
        
        return signals
    
    def _calculate_ambiguity_score(self, signals: List[AmbiguitySignal], result: CommandResult) -> float:
        """Calcular puntuaci칩n de ambig칲edad basada en las se침ales detectadas"""
        if not signals:
            return 0.0
        
        # Peso base de la suma de severidades
        total_severity = sum(signal.severity for signal in signals)
        signal_count = len(signals)
        
        # Normalizar por n칰mero de se침ales (evitar que muchas se침ales leves dominen)
        base_score = total_severity / max(signal_count, 1)
        
        # Ajustar por confianza del resultado original
        confidence_penalty = (1.0 - result.confidence) * 0.3
        
        # Penalizar m치s si hay se침ales de alta severidad
        high_severity_signals = [s for s in signals if s.severity > 0.7]
        high_severity_bonus = len(high_severity_signals) * 0.1
        
        final_score = min(1.0, base_score + confidence_penalty + high_severity_bonus)
        
        return final_score
    
    def _generate_alternative_interpretations(self, user_input: str, result: CommandResult, 
                                            signals: List[AmbiguitySignal], 
                                            context: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]]:
        """Generar interpretaciones alternativas basadas en las se침ales de ambig칲edad"""
        interpretations = []
        
        # Interpretaci칩n original
        interpretations.append({
            'type': 'original',
            'action': result.action,
            'target': result.target,
            'confidence': result.confidence,
            'description': f"Interpretaci칩n original: {result.action} - {result.target}"
        })
        
        # Generar alternativas basadas en se침ales
        for signal in signals:
            if signal.signal_type == 'multiple_interpretations':
                apps = signal.context_data.get('possible_apps', [])
                for app in apps[:2]:  # M치ximo 2 alternativas por se침al
                    interpretations.append({
                        'type': 'alternative_app',
                        'action': result.action,
                        'target': app,
                        'confidence': result.confidence * 0.8,
                        'description': f"Alternativa: {result.action} - {app}",
                        'source_signal': signal.signal_type
                    })
            
            elif signal.signal_type == 'conflicting_targets':
                found_apps = signal.context_data.get('found_apps', [])
                for app, category in found_apps:
                    if app != result.target:
                        interpretations.append({
                            'type': 'conflicting_target',
                            'action': result.action,
                            'target': app,
                            'confidence': result.confidence * 0.7,
                            'description': f"Target alternativo: {result.action} - {app} ({category})",
                            'source_signal': signal.signal_type
                        })
        
        # Limitar a m치ximo 5 interpretaciones
        return interpretations[:5]
    
    def _calculate_confidence_factors(self, user_input: str, result: CommandResult, 
                                    signals: List[AmbiguitySignal], 
                                    context: Optional[Dict[str, Any]] = None) -> Dict[str, float]:
        """Calcular factores que afectan la confianza"""
        factors = {}
        
        # Factor de longitud del input
        word_count = len(user_input.split())
        factors['input_length'] = min(1.0, word_count / 5.0)  # 칍ptimo alrededor de 5 palabras
        
        # Factor de especificidad
        specific_terms = len([word for word in user_input.lower().split() 
                            if len(word) > 4 and word not in ['que', 'para', 'con', 'por']])
        factors['specificity'] = min(1.0, specific_terms / 3.0)
        
        # Factor de contexto disponible
        factors['context_availability'] = 1.0 if context and context.get('recent_commands') else 0.3
        
        # Factor inverso de ambig칲edad
        factors['clarity'] = 1.0 - (len(signals) * 0.2)
        
        # Factor de confianza original
        factors['original_confidence'] = result.confidence
        
        return factors
    
    def _determine_recommended_action(self, ambiguity_score: float, confidence: float, 
                                    signals: List[AmbiguitySignal]) -> str:
        """Determinar la acci칩n recomendada basada en el an치lisis"""
        
        # Si hay se침ales cr칤ticas, siempre clarificar
        critical_signals = [s for s in signals if s.severity > 0.8]
        if critical_signals:
            return 'clarify'
        
        # Si la ambig칲edad es alta, clarificar
        if ambiguity_score > 0.7:
            return 'clarify'
        
        # Si la confianza es muy baja, clarificar
        if confidence < 0.5:
            return 'clarify'
        
        # Si hay m칰ltiples interpretaciones viables, sugerir alternativas
        if ambiguity_score > 0.4 and confidence > 0.6:
            return 'suggest_alternatives'
        
        # Si todo est치 bien, ejecutar
        return 'execute'
    
    def _generate_clarification_questions(self, signals: List[AmbiguitySignal], 
                                        user_input: str, 
                                        interpretations: List[Dict[str, Any]]) -> List[str]:
        """Generar preguntas de clarificaci칩n inteligentes"""
        questions = []
        
        # Recopilar sugerencias de todas las se침ales
        for signal in signals:
            questions.extend(signal.suggested_clarifications)
        
        # Agregar preguntas basadas en interpretaciones alternativas
        if len(interpretations) > 1:
            questions.append("He encontrado varias posibilidades:")
            for i, interp in enumerate(interpretations[1:4], 1):  # M치ximo 3 alternativas
                questions.append(f"{i}. {interp['description']}")
            questions.append("쮺u치l prefieres?")
        
        # Eliminar duplicados manteniendo orden
        unique_questions = []
        for q in questions:
            if q not in unique_questions:
                unique_questions.append(q)
        
        return unique_questions[:5]  # M치ximo 5 preguntas
    
    def _find_similar_app_names(self, target: str) -> List[str]:
        """Encontrar nombres de aplicaciones similares al target"""
        if not target:
            return []
        
        similar = []
        target_lower = target.lower()
        
        # Buscar en aplicaciones conocidas
        for category, apps in self.known_apps.items():
            for app in apps:
                if (target_lower in app.lower() or 
                    app.lower() in target_lower or 
                    self._calculate_similarity(target_lower, app.lower()) > 0.7):
                    similar.append(app)
        
        return similar[:5]  # M치ximo 5 similares
    
    def _calculate_similarity(self, str1: str, str2: str) -> float:
        """Calcular similitud simple entre dos strings"""
        if not str1 or not str2:
            return 0.0
        
        # Similitud basada en caracteres comunes
        common_chars = set(str1) & set(str2)
        total_chars = set(str1) | set(str2)
        
        if not total_chars:
            return 0.0
        
        return len(common_chars) / len(total_chars)
    
    def update_context(self, user_input: str, result: CommandResult):
        """Actualizar contexto para futuros an치lisis"""
        command_record = {
            'timestamp': datetime.now().isoformat(),
            'user_input': user_input,
            'action': result.action,
            'target': result.target,
            'confidence': result.confidence,
            'command_type': result.command_type
        }
        
        self.recent_commands.append(command_record)
        
        # Mantener solo los 칰ltimos 10 comandos
        if len(self.recent_commands) > 10:
            self.recent_commands = self.recent_commands[-10:]

class PreExecutionValidator:
    """
    Validador inteligente pre-ejecuci칩n para comandos ambiguos
    Realiza verificaciones del estado del sistema, contexto del usuario,
    uso de recursos y posibles conflictos antes de ejecutar comandos.
    """
    
    def __init__(self):
        self.validation_history: List[Dict[str, Any]] = []
        self.system_thresholds = {
            'cpu_usage_max': 80.0,      # % CPU m치ximo
            'memory_usage_max': 85.0,    # % RAM m치ximo
            'user_idle_min': 30.0,       # segundos m칤nimos de inactividad para comandos intrusivos
            'command_frequency_max': 5,   # m치ximo comandos por minuto
        }
        self.quiet_hours = {
            'start': 22,  # 10 PM
            'end': 7      # 7 AM
        }
        
    def validate_before_execution(self, context: ValidationContext) -> ValidationResult:
        """
        Validaci칩n inteligente antes de ejecutar comando
        
        Args:
            context: Contexto de validaci칩n con comando y estado del sistema
            
        Returns:
            ValidationResult: Resultado de la validaci칩n con recomendaciones
        """
        print(f"游댌 Validando comando: {context.command_result.action} - {context.command_result.target}")
        
        warnings = []
        blocking_issues = []
        recommendations = []
        confidence_score = 1.0
        execution_delay = 0
        
        # Realizar todas las verificaciones
        checks = [
            self._check_system_state(context),
            self._check_user_context(context),
            self._check_resource_usage(context),
            self._check_time_appropriateness(context),
            self._check_potential_conflicts(context),
            self._check_command_frequency(context),
            self._check_app_already_running(context)
        ]
        
        # Procesar resultados de verificaciones
        for check_result in checks:
            if check_result['blocking']:
                blocking_issues.extend(check_result['issues'])
                confidence_score *= 0.3
            if check_result['warnings']:
                warnings.extend(check_result['warnings'])
                confidence_score *= check_result.get('confidence_penalty', 0.8)
            if check_result['recommendations']:
                recommendations.extend(check_result['recommendations'])
            if check_result.get('delay', 0) > execution_delay:
                execution_delay = check_result['delay']
        
        # Determinar si debe ejecutarse
        should_execute = len(blocking_issues) == 0 and confidence_score > 0.3
        
        # Guardar en historial
        self._save_validation_history(context, should_execute, confidence_score)
        
        return ValidationResult(
            should_execute=should_execute,
            confidence_score=confidence_score,
            warnings=warnings,
            blocking_issues=blocking_issues,
            recommendations=recommendations,
            execution_delay=execution_delay
        )
    
    def _check_system_state(self, context: ValidationContext) -> Dict[str, Any]:
        """Verificar estado general del sistema"""
        issues = []
        warnings = []
        recommendations = []
        blocking = False
        confidence_penalty = 1.0
        
        try:
            # Verificar si el sistema est치 sobrecargado
            if context.system_state.cpu_usage > self.system_thresholds['cpu_usage_max']:
                if context.command_result.command_type in ['app', 'music']:
                    blocking = True
                    issues.append(f"CPU sobrecargada ({context.system_state.cpu_usage:.1f}%)")
                    recommendations.append("Esperar a que baje el uso de CPU")
                else:
                    warnings.append(f"CPU alta ({context.system_state.cpu_usage:.1f}%)")
                    confidence_penalty = 0.7
            
            if context.system_state.memory_usage > self.system_thresholds['memory_usage_max']:
                if context.command_result.command_type == 'app':
                    warnings.append(f"Memoria alta ({context.system_state.memory_usage:.1f}%)")
                    recommendations.append("Considerar cerrar aplicaciones no usadas")
                    confidence_penalty = 0.8
        
        except Exception as e:
            warnings.append(f"Error verificando estado del sistema: {e}")
            confidence_penalty = 0.9
        
        return {
            'blocking': blocking,
            'issues': issues,
            'warnings': warnings,
            'recommendations': recommendations,
            'confidence_penalty': confidence_penalty
        }
    
    def _check_user_context(self, context: ValidationContext) -> Dict[str, Any]:
        """Verificar contexto del usuario (actividad, ocupaci칩n)"""
        issues = []
        warnings = []
        recommendations = []
        blocking = False
        delay = 0
        
        try:
            # Verificar si el usuario est치 activo
            if context.system_state.user_idle_time < self.system_thresholds['user_idle_min']:
                if context.command_result.action in ['open_app', 'search_content']:
                    # Usuario activo, comando intrusivo
                    warnings.append("Usuario activo, comando puede interrumpir trabajo")
                    recommendations.append("Esperar momento m치s apropiado o pedir confirmaci칩n")
                    delay = 5  # Esperar 5 segundos
            
            # Verificar si hay aplicaciones de trabajo/estudio abiertas
            work_apps = ['code', 'visual studio', 'word', 'excel', 'powerpoint', 'teams', 'zoom']
            active_work_apps = [app for app in work_apps 
                              if any(work_app in proc.lower() for proc in context.system_state.running_processes 
                                   for work_app in [app])]
            
            if active_work_apps and context.command_result.command_type in ['music', 'content']:
                warnings.append(f"Aplicaciones de trabajo activas: {', '.join(active_work_apps)}")
                recommendations.append("Usar volumen bajo o auriculares")
        
        except Exception as e:
            warnings.append(f"Error verificando contexto del usuario: {e}")
        
        return {
            'blocking': blocking,
            'issues': issues,
            'warnings': warnings,
            'recommendations': recommendations,
            'delay': delay
        }
    
    def _check_resource_usage(self, context: ValidationContext) -> Dict[str, Any]:
        """Verificar uso de recursos del sistema"""
        issues = []
        warnings = []
        recommendations = []
        blocking = False
        
        try:
            # Verificar espacio en disco para apps que lo requieren
            if context.command_result.action == 'open_app':
                disk_usage = psutil.disk_usage('/')
                free_gb = disk_usage.free / (1024**3)
                
                if free_gb < 1.0:  # Menos de 1GB libre
                    blocking = True
                    issues.append(f"Poco espacio en disco ({free_gb:.1f}GB libre)")
                    recommendations.append("Liberar espacio en disco antes de abrir aplicaciones")
                elif free_gb < 5.0:  # Menos de 5GB libre
                    warnings.append(f"Espacio en disco limitado ({free_gb:.1f}GB libre)")
            
            # Verificar conexi칩n de red para comandos que la requieren
            if context.command_result.command_type in ['music', 'content']:
                # Verificaci칩n b치sica de conectividad (esto se podr칤a mejorar)
                try:
                    import socket
                    socket.create_connection(("8.8.8.8", 53), timeout=3)
                except (socket.error, OSError):
                    blocking = True
                    issues.append("Sin conexi칩n a internet")
                    recommendations.append("Verificar conexi칩n de red")
        
        except Exception as e:
            warnings.append(f"Error verificando recursos: {e}")
        
        return {
            'blocking': blocking,
            'issues': issues,
            'warnings': warnings,
            'recommendations': recommendations
        }
    
    def _check_time_appropriateness(self, context: ValidationContext) -> Dict[str, Any]:
        """Verificar si es momento apropiado para el comando"""
        issues = []
        warnings = []
        recommendations = []
        blocking = False
        
        try:
            current_hour = context.system_state.current_time.hour
            
            # Verificar horas de silencio
            if (current_hour >= self.quiet_hours['start'] or 
                current_hour < self.quiet_hours['end']):
                
                if context.command_result.command_type == 'music':
                    warnings.append(f"Horas de silencio ({self.quiet_hours['start']}:00-{self.quiet_hours['end']}:00)")
                    recommendations.append("Considerar usar auriculares o volumen bajo")
                elif context.command_result.action == 'open_app' and context.command_result.target in ['spotify', 'youtube']:
                    warnings.append("Aplicaci칩n de audio en horas de silencio")
                    recommendations.append("Recordar usar auriculares")
            
            # Verificar d칤as laborables vs fines de semana
            is_weekend = context.system_state.current_time.weekday() >= 5
            is_work_hours = 9 <= current_hour <= 17
            
            if not is_weekend and is_work_hours:
                if context.command_result.command_type == 'content':
                    warnings.append("Horario laboral, comando de entretenimiento")
                    recommendations.append("Considerar si es apropiado durante trabajo")
        
        except Exception as e:
            warnings.append(f"Error verificando tiempo: {e}")
        
        return {
            'blocking': blocking,
            'issues': issues,
            'warnings': warnings,
            'recommendations': recommendations
        }
    
    def _check_potential_conflicts(self, context: ValidationContext) -> Dict[str, Any]:
        """Verificar conflictos potenciales con otras aplicaciones"""
        issues = []
        warnings = []
        recommendations = []
        blocking = False
        
        try:
            target_app = context.command_result.target
            if not target_app:
                return {'blocking': False, 'issues': [], 'warnings': [], 'recommendations': []}
            
            # Definir conflictos conocidos
            app_conflicts = {
                'spotify': ['youtube', 'vlc', 'windows media player'],
                'youtube': ['spotify', 'vlc'],
                'chrome': ['firefox', 'edge'],
                'steam': ['epic games', 'origin', 'uplay'],
            }
            
            target_lower = target_app.lower()
            if target_lower in app_conflicts:
                conflicting_apps = app_conflicts[target_lower]
                
                # Verificar si hay aplicaciones conflictivas ejecut치ndose
                running_conflicts = []
                for proc in context.system_state.running_processes:
                    for conflict_app in conflicting_apps:
                        if conflict_app.replace(' ', '') in proc.lower().replace(' ', ''):
                            running_conflicts.append(conflict_app)
                
                if running_conflicts:
                    warnings.append(f"Aplicaciones conflictivas ejecut치ndose: {', '.join(running_conflicts)}")
                    recommendations.append(f"Considerar cerrar {', '.join(running_conflicts)} antes de abrir {target_app}")
            
            # Verificar l칤mites de aplicaciones similares
            if context.command_result.command_type == 'music':
                music_apps_running = sum(1 for proc in context.system_state.running_processes 
                                       if any(music_app in proc.lower() 
                                            for music_app in ['spotify', 'youtube', 'vlc', 'media player']))
                
                if music_apps_running >= 2:
                    warnings.append(f"M칰ltiples aplicaciones de m칰sica ejecut치ndose ({music_apps_running})")
                    recommendations.append("Considerar cerrar otras aplicaciones de m칰sica")
        
        except Exception as e:
            warnings.append(f"Error verificando conflictos: {e}")
        
        return {
            'blocking': blocking,
            'issues': issues,
            'warnings': warnings,
            'recommendations': recommendations
        }
    
    def _check_command_frequency(self, context: ValidationContext) -> Dict[str, Any]:
        """Verificar frecuencia de comandos para evitar spam"""
        issues = []
        warnings = []
        recommendations = []
        blocking = False
        
        try:
            # Contar comandos recientes (칰ltimo minuto)
            recent_commands = [cmd for cmd in context.recent_commands 
                             if cmd.get('timestamp', 0) > time.time() - 60]
            
            if len(recent_commands) > self.system_thresholds['command_frequency_max']:
                blocking = True
                issues.append(f"Demasiados comandos recientes ({len(recent_commands)} en 1 minuto)")
                recommendations.append("Esperar antes de ejecutar m치s comandos")
            elif len(recent_commands) > 3:
                warnings.append(f"Frecuencia alta de comandos ({len(recent_commands)} en 1 minuto)")
                recommendations.append("Considerar ralentizar los comandos")
            
            # Verificar comandos duplicados recientes
            similar_recent = [cmd for cmd in recent_commands 
                            if (cmd.get('action') == context.command_result.action and 
                                cmd.get('target') == context.command_result.target)]
            
            if len(similar_recent) > 0:
                warnings.append("Comando similar ejecutado recientemente")
                recommendations.append("Verificar si el comando anterior funcion칩")
        
        except Exception as e:
            warnings.append(f"Error verificando frecuencia: {e}")
        
        return {
            'blocking': blocking,
            'issues': issues,
            'warnings': warnings,
            'recommendations': recommendations
        }
    
    def _check_app_already_running(self, context: ValidationContext) -> Dict[str, Any]:
        """Verificar si la aplicaci칩n ya est치 ejecut치ndose"""
        issues = []
        warnings = []
        recommendations = []
        blocking = False
        
        try:
            if (context.command_result.action == 'open_app' and 
                context.command_result.target):
                
                target_app = context.command_result.target.lower()
                
                # Verificar si la app ya est치 ejecut치ndose
                app_running = any(target_app in proc.lower() 
                                for proc in context.system_state.running_processes)
                
                if app_running:
                    warnings.append(f"{context.command_result.target} ya est치 ejecut치ndose")
                    recommendations.append(f"Enfocar ventana existente en lugar de abrir nueva instancia")
                    # No bloquear, pero reducir confianza
                    return {
                        'blocking': False,
                        'issues': [],
                        'warnings': warnings,
                        'recommendations': recommendations,
                        'confidence_penalty': 0.6
                    }
        
        except Exception as e:
            warnings.append(f"Error verificando aplicaciones ejecut치ndose: {e}")
        
        return {
            'blocking': blocking,
            'issues': issues,
            'warnings': warnings,
            'recommendations': recommendations
        }
    
    def _save_validation_history(self, context: ValidationContext, should_execute: bool, confidence_score: float):
        """Guardar historial de validaciones para aprendizaje"""
        try:
            history_entry = {
                'timestamp': time.time(),
                'user_input': context.user_input,
                'command_type': context.command_result.command_type,
                'action': context.command_result.action,
                'target': context.command_result.target,
                'should_execute': should_execute,
                'confidence_score': confidence_score,
                'system_cpu': context.system_state.cpu_usage,
                'system_memory': context.system_state.memory_usage,
                'user_idle_time': context.system_state.user_idle_time
            }
            
            self.validation_history.append(history_entry)
            
            # Mantener solo los 칰ltimos 100 registros
            if len(self.validation_history) > 100:
                self.validation_history = self.validation_history[-100:]
        
        except Exception as e:
            print(f"丘멆잺 Error guardando historial de validaci칩n: {e}")
    
    def get_validation_stats(self) -> Dict[str, Any]:
        """Obtener estad칤sticas de validaciones"""
        if not self.validation_history:
            return {'total_validations': 0}
        
        total = len(self.validation_history)
        executed = sum(1 for entry in self.validation_history if entry['should_execute'])
        blocked = total - executed
        
        avg_confidence = sum(entry['confidence_score'] for entry in self.validation_history) / total
        
        return {
            'total_validations': total,
            'executed': executed,
            'blocked': blocked,
            'execution_rate': executed / total if total > 0 else 0,
            'average_confidence': avg_confidence,
            'recent_validations': self.validation_history[-10:]
        }

class DynamicConfidenceCalculator:
    """
    游꿢 Sistema de Confianza Din치mico
    ================================
    Calcula confianza basada en m칰ltiples factores contextuales y de aprendizaje
    """
    
    def __init__(self, learning_system: Optional['LearningSystem'] = None):
        self.learning_system = learning_system
        
        # 游꿢 Pesos para diferentes factores de confianza
        self.confidence_weights = {
            'ollama_confidence': 0.35,      # Base de Ollama
            'historical_success': 0.20,     # 칄xito hist칩rico del comando
            'context_clarity': 0.15,        # Claridad del contexto
            'user_pattern_match': 0.15,     # Coincidencia con patrones del usuario
            'system_state': 0.10,           # Estado del sistema
            'ambiguity_score': 0.05         # Puntuaci칩n de ambig칲edad invertida
        }
        
        # 游늵 Cache de estad칤sticas para optimizar c치lculos
        self._stats_cache = {}
        self._cache_timestamp = 0
        self._cache_ttl = 300  # 5 minutos
        
        # 游꿢 Umbrales de confianza
        self.confidence_thresholds = {
            'very_high': 0.9,    # Ejecutar inmediatamente
            'high': 0.7,         # Ejecutar con confirmaci칩n opcional (AJUSTADO: era 0.75)
            'medium': 0.5,       # Pedir confirmaci칩n (AJUSTADO: era 0.6)
            'low': 0.3,          # Sugerir alternativas (AJUSTADO: era 0.4)
            'very_low': 0.15     # Rechazar o pedir clarificaci칩n (AJUSTADO: era 0.2)
        }
        
        # 游늳 Factores de ajuste din치mico
        self.dynamic_adjustments = {
            'time_of_day': True,      # Ajustar seg칰n hora del d칤a
            'user_activity': True,    # Considerar actividad reciente
            'command_frequency': True, # Frecuencia de uso del comando
            'error_rate': True        # Tasa de error reciente
        }
    
    def calculate_confidence(self, result: CommandResult, context: Optional[dict] = None) -> float:
        """
        游꿢 Calcular confianza din치micamente basada en m칰ltiples factores
        
        Args:
            result: Resultado del comando a evaluar
            context: Contexto adicional (memoria, historial, etc.)
            
        Returns:
            float: Puntuaci칩n de confianza (0.0 - 1.0)
        """
        if context is None:
            context = {}
            
        # 游늵 Calcular factores individuales
        factors = {
            'ollama_confidence': result.confidence,
            'historical_success': self._get_historical_success(result.action, result.command_type),
            'context_clarity': self._analyze_context_clarity(context, result),
            'user_pattern_match': self._check_user_patterns(result, context),
            'system_state': self._check_system_readiness(result.command_type),
            'ambiguity_score': 1.0 - self._calculate_ambiguity_penalty(result, context)
        }
        
        # 游꿢 Aplicar ajustes din치micos
        adjusted_factors = self._apply_dynamic_adjustments(factors, result, context)
        
        # 游늳 Calcular confianza ponderada
        final_confidence = self._weighted_average(adjusted_factors)
        
        # 游꿢 Aplicar l칤mites y normalizaci칩n
        final_confidence = max(0.0, min(1.0, final_confidence))
        
        # 游닇 Log detallado para debugging
        self._log_confidence_calculation(result, factors, adjusted_factors, final_confidence)
        
        return final_confidence
    
    def get_confidence_level(self, confidence: float) -> str:
        """Obtener nivel de confianza textual"""
        if confidence >= self.confidence_thresholds['very_high']:
            return 'very_high'
        elif confidence >= self.confidence_thresholds['high']:
            return 'high'
        elif confidence >= self.confidence_thresholds['medium']:
            return 'medium'
        elif confidence >= self.confidence_thresholds['low']:
            return 'low'
        else:
            return 'very_low'
    
    def should_execute_immediately(self, confidence: float) -> bool:
        """Determinar si ejecutar inmediatamente sin confirmaci칩n"""
        return confidence >= self.confidence_thresholds['very_high']
    
    def should_request_confirmation(self, confidence: float) -> bool:
        """Determinar si pedir confirmaci칩n antes de ejecutar"""
        return self.confidence_thresholds['low'] <= confidence < self.confidence_thresholds['high']
    
    def _get_historical_success(self, action: str, command_type: str) -> float:
        """游늵 Calcular tasa de 칠xito hist칩rica para este tipo de comando"""
        if not self.learning_system:
            return 0.7  # Valor por defecto
        
        try:
            # Obtener estad칤sticas de 칠xito/fallo
            success_count = len([s for s in self.learning_system.success_patterns 
                               if s.get('action') == action and s.get('command_type') == command_type])
            
            failure_count = len([f for f in self.learning_system.failure_patterns 
                               if f.intended_action == action and f.command_type == command_type])
            
            total_attempts = success_count + failure_count
            
            if total_attempts == 0:
                return 0.7  # Sin historial, asumir competencia media
            
            success_rate = success_count / total_attempts
            
            # 游늳 Ajustar por volumen de datos (m치s datos = m치s confiable)
            confidence_in_data = min(1.0, total_attempts / 10.0)  # M치xima confianza con 10+ intentos
            
            return success_rate * confidence_in_data + 0.5 * (1 - confidence_in_data)
            
        except Exception as e:
            print(f"丘멆잺 Error calculando 칠xito hist칩rico: {e}")
            return 0.6
    
    def _analyze_context_clarity(self, context: dict, result: CommandResult) -> float:
        """游댌 Analizar claridad del contexto disponible"""
        clarity_score = 0.5  # Base
        
        try:
            # 游닇 Factor 1: Disponibilidad de contexto de memoria
            if context.get('memory_context'):
                memory_ctx = context['memory_context']
                if memory_ctx.get('relevant_facts'):
                    clarity_score += 0.2
                if memory_ctx.get('user_preferences'):
                    clarity_score += 0.15
            
            # 游닇 Factor 2: Especificidad del target
            if result.target:
                if len(result.target) > 3:  # Target espec칤fico
                    clarity_score += 0.1
                if any(char.isdigit() for char in result.target):  # Contiene n칰meros/versiones
                    clarity_score += 0.05
            
            # 游닇 Factor 3: Datos de ejecuci칩n disponibles
            if result.execution_data:
                if len(result.execution_data) > 2:  # M칰ltiples par치metros
                    clarity_score += 0.1
            
            # 游닇 Factor 4: Contexto de comandos recientes
            if context.get('recent_commands'):
                recent = context['recent_commands']
                if len(recent) > 0:
                    clarity_score += 0.05
                    # Bonus si hay comandos relacionados
                    related_commands = [cmd for cmd in recent 
                                      if cmd.get('command_type') == result.command_type]
                    if related_commands:
                        clarity_score += 0.05
            
            return min(1.0, clarity_score)
            
        except Exception as e:
            print(f"丘멆잺 Error analizando claridad de contexto: {e}")
            return 0.5
    
    def _check_user_patterns(self, result: CommandResult, context: dict) -> float:
        """游녻 Verificar coincidencia con patrones de usuario conocidos"""
        pattern_match = 0.5  # Base
        
        try:
            memory_context = context.get('memory_context', {})
            user_preferences = memory_context.get('user_preferences', {})
            
            # 游꿧 Patrones musicales
            if result.command_type == 'music':
                if result.target:
                    # Verificar si coincide con gustos musicales conocidos
                    favorite_artists = user_preferences.get('favorite_artists', [])
                    favorite_genres = user_preferences.get('favorite_genres', [])
                    
                    target_lower = result.target.lower()
                    if any(artist.lower() in target_lower for artist in favorite_artists):
                        pattern_match += 0.3
                    if any(genre.lower() in target_lower for genre in favorite_genres):
                        pattern_match += 0.2
            
            # 游님 Patrones de aplicaciones
            elif result.command_type == 'app':
                frequently_used_apps = user_preferences.get('frequently_used_apps', [])
                if result.target and result.target.lower() in [app.lower() for app in frequently_used_apps]:
                    pattern_match += 0.3
            
            # 游꿟 Patrones de contenido
            elif result.command_type == 'content':
                favorite_shows = user_preferences.get('favorite_shows', [])
                favorite_genres = user_preferences.get('favorite_content_genres', [])
                
                if result.target:
                    target_lower = result.target.lower()
                    if any(show.lower() in target_lower for show in favorite_shows):
                        pattern_match += 0.3
                    if any(genre.lower() in target_lower for genre in favorite_genres):
                        pattern_match += 0.2
            
            # 游늵 Factor de frecuencia de uso
            recent_commands = context.get('recent_commands', [])
            similar_recent = [cmd for cmd in recent_commands 
                             if cmd.get('action') == result.action and 
                                cmd.get('command_type') == result.command_type]
            
            if len(similar_recent) > 0:
                frequency_bonus = min(0.2, len(similar_recent) * 0.05)
                pattern_match += frequency_bonus
            
            return min(1.0, pattern_match)
            
        except Exception as e:
            print(f"丘멆잺 Error verificando patrones de usuario: {e}")
            return 0.5
    
    def _check_system_readiness(self, command_type: str) -> float:
        """游눹 Verificar estado del sistema para ejecutar el comando"""
        readiness = 0.8  # Base optimista
        
        try:
            # 游늵 Verificar recursos del sistema
            cpu_usage = psutil.cpu_percent(interval=0.1)
            memory_usage = psutil.virtual_memory().percent
            
            # 游늳 Penalizar por alto uso de recursos
            if cpu_usage > 80:
                readiness -= 0.3
            elif cpu_usage > 60:
                readiness -= 0.1
            
            if memory_usage > 85:
                readiness -= 0.2
            elif memory_usage > 70:
                readiness -= 0.1
            
            # 游꿢 Ajustes espec칤ficos por tipo de comando
            if command_type == 'app':
                # Verificar si hay muchas apps abiertas
                running_processes = len([p for p in psutil.process_iter(['name']) 
                                       if '.exe' in p.info['name']])
                if running_processes > 50:
                    readiness -= 0.1
            
            elif command_type == 'music':
                # Verificar disponibilidad de audio
                try:
                    import pygame
                    if not pygame.mixer.get_init():
                        readiness -= 0.2
                except:
                    readiness -= 0.1
            
            return max(0.0, min(1.0, readiness))
            
        except Exception as e:
            print(f"丘멆잺 Error verificando estado del sistema: {e}")
            return 0.7
    
    def _calculate_ambiguity_penalty(self, result: CommandResult, context: dict) -> float:
        """游댌 Calcular penalizaci칩n por ambig칲edad detectada"""
        penalty = 0.0
        
        try:
            # Si hay an치lisis de ambig칲edad disponible
            ambiguity_analysis = context.get('ambiguity_analysis')
            if ambiguity_analysis:
                penalty = ambiguity_analysis.ambiguity_score * 0.5
            
            # Verificaciones b치sicas de ambig칲edad
            if not result.target or len(result.target) < 3:
                penalty += 0.1
            
            if result.action in ['chat', 'unknown']:
                penalty += 0.2
            
            # Penalizar comandos que necesitan clarificaci칩n
            if result.needs_clarification:
                penalty += 0.3
            
            return min(1.0, penalty)
            
        except Exception as e:
            print(f"丘멆잺 Error calculando penalizaci칩n de ambig칲edad: {e}")
            return 0.1
    
    def _apply_dynamic_adjustments(self, factors: dict, result: CommandResult, context: dict) -> dict:
        """游꿢 Aplicar ajustes din치micos basados en contexto temporal y de uso"""
        adjusted_factors = factors.copy()
        
        try:
            current_time = datetime.now()
            
            # 游뎷 Ajuste por hora del d칤a
            if self.dynamic_adjustments['time_of_day']:
                hour = current_time.hour
                
                # Comandos de m칰sica m치s confiables en horas de ocio
                if result.command_type == 'music':
                    if 18 <= hour <= 23 or 10 <= hour <= 14:  # Tarde/noche o ma침ana relajada
                        adjusted_factors['user_pattern_match'] *= 1.1
                
                # Comandos de trabajo m치s confiables en horas laborales
                elif result.command_type == 'app' and result.target:
                    work_apps = ['word', 'excel', 'powerpoint', 'teams', 'outlook']
                    if any(app in result.target.lower() for app in work_apps):
                        if 8 <= hour <= 18:  # Horario laboral
                            adjusted_factors['context_clarity'] *= 1.1
            
            # 游늵 Ajuste por frecuencia de uso
            if self.dynamic_adjustments['command_frequency']:
                recent_commands = context.get('recent_commands', [])
                same_type_commands = [cmd for cmd in recent_commands[-10:] 
                                    if cmd.get('command_type') == result.command_type]
                
                frequency_ratio = len(same_type_commands) / 10.0
                if frequency_ratio > 0.3:  # Comando usado frecuentemente
                    adjusted_factors['historical_success'] *= 1.1
                elif frequency_ratio < 0.1:  # Comando poco usado
                    adjusted_factors['historical_success'] *= 0.9
            
            # 丘멆잺 Ajuste por tasa de errores reciente
            if self.dynamic_adjustments['error_rate'] and self.learning_system:
                recent_failures = [f for f in self.learning_system.failure_patterns 
                                 if f.timestamp > current_time - timedelta(hours=1)]
                
                if len(recent_failures) > 3:  # Muchos errores recientes
                    adjusted_factors['system_state'] *= 0.8
                    adjusted_factors['ollama_confidence'] *= 0.9
            
            return adjusted_factors
            
        except Exception as e:
            print(f"丘멆잺 Error aplicando ajustes din치micos: {e}")
            return factors
    
    def _weighted_average(self, factors: dict) -> float:
        """游늵 Calcular promedio ponderado de factores de confianza"""
        try:
            total_weight = 0.0
            weighted_sum = 0.0
            
            for factor_name, value in factors.items():
                weight = self.confidence_weights.get(factor_name, 0.1)
                weighted_sum += value * weight
                total_weight += weight
            
            if total_weight == 0:
                return 0.5
            
            return weighted_sum / total_weight
            
        except Exception as e:
            print(f"丘멆잺 Error calculando promedio ponderado: {e}")
            return 0.5
    
    def _log_confidence_calculation(self, result: CommandResult, factors: dict, 
                                   adjusted_factors: dict, final_confidence: float):
        """游닇 Log detallado del c치lculo de confianza para debugging"""
        try:
            print(f"游꿢 C츼LCULO DE CONFIANZA DIN츼MICO:")
            print(f"   Comando: {result.command_type}  {result.action} ({result.target})")
            print(f"   Factores originales:")
            for factor, value in factors.items():
                print(f"      {factor}: {value:.3f}")
            print(f"   Factores ajustados:")
            for factor, value in adjusted_factors.items():
                if abs(value - factors[factor]) > 0.001:
                    print(f"      {factor}: {value:.3f} (ajustado desde {factors[factor]:.3f})")
            print(f"   Confianza final: {final_confidence:.3f} ({self.get_confidence_level(final_confidence)})")
            
        except Exception as e:
            print(f"丘멆잺 Error en log de confianza: {e}")
    
    def get_confidence_explanation(self, result: CommandResult, confidence: float, 
                                 factors: Optional[dict] = None) -> str:
        """游닇 Generar explicaci칩n textual de la confianza calculada"""
        try:
            level = self.get_confidence_level(confidence)
            
            explanations = {
                'very_high': "Tengo muy alta confianza en este comando",
                'high': "Tengo alta confianza en este comando",
                'medium': "Tengo confianza moderada en este comando",
                'low': "Tengo poca confianza en este comando",
                'very_low': "Tengo muy poca confianza en este comando"
            }
            
            base_explanation = explanations.get(level, "Confianza indeterminada")
            
            # Agregar detalles espec칤ficos si est치n disponibles
            details = []
            if factors:
                if factors.get('historical_success', 0) > 0.8:
                    details.append("historial exitoso")
                elif factors.get('historical_success', 0) < 0.4:
                    details.append("historial con errores")
                
                if factors.get('context_clarity', 0) > 0.8:
                    details.append("contexto claro")
                elif factors.get('context_clarity', 0) < 0.4:
                    details.append("contexto ambiguo")
                
                if factors.get('user_pattern_match', 0) > 0.8:
                    details.append("coincide con tus preferencias")
            
            if details:
                base_explanation += f" ({', '.join(details)})"
            
            return base_explanation
            
        except Exception as e:
            print(f"丘멆잺 Error generando explicaci칩n de confianza: {e}")
            return "Confianza calculada"

class UnifiedCommandDetector:
    def __init__(self, grok_callback=None):
        """
        Inicializar detector unificado simplificado
        """
        self.grok_callback = grok_callback
        self.model = "llama3"
        
        # 游 INICIALIZAR MEMORIA CONVERSACIONAL PERSISTENTE
        if CONVERSATION_MEMORY_AVAILABLE:
            try:
                self.conversation_memory = ConversationMemory()
                print("游 Sistema de memoria conversacional activado")
            except Exception as e:
                print(f"丘멆잺 Error inicializando memoria conversacional: {e}")
                self.conversation_memory = None
        else:
            self.conversation_memory = None
        
        # Inicializar puente de memoria (para CRUD personality.yaml)
        if MEMORY_BRIDGE_AVAILABLE:
            try:
                self.memory_bridge = MemoryBridge()
            except Exception:
                self.memory_bridge = None
        else:
            self.memory_bridge = None
        
        # Inicializar controlador de m칰sica avanzado
        if ADVANCED_MUSIC_AVAILABLE:
            self.music_controller = AdvancedMusicController()
        else:
            self.music_controller = None
        
        # Inicializar controlador de Spotify Unificado (PRIORIDAD ALTA)
        if SPOTIFY_API_AVAILABLE:
            self.spotify_controller_unified = SpotifyControllerUnified()
            print("游꿧 Controlador Spotify Unificado disponible - Reproducci칩n directa habilitada")
        else:
            self.spotify_controller_unified = None
        
        # Inicializar Selector Inteligente de M칰sica
        if INTELLIGENT_SELECTOR_AVAILABLE and SPOTIFY_API_AVAILABLE:
            self.intelligent_selector = IntelligentMusicSelector()
            print("游 Selector Inteligente de M칰sica disponible - Selecci칩n personalizada habilitada")
        else:
            self.intelligent_selector = None
        
        # 游댢 INICIALIZAR CORRECTOR AUTOM츼TICO DE COMANDOS
        if AUTOMATIC_CORRECTOR_AVAILABLE:
            self.command_corrector = AutomaticCommandCorrector()
            print("游댢 Corrector Autom치tico de Comandos disponible - Correcci칩n inteligente habilitada")
        else:
            self.command_corrector = None
        
        # 游댌 INICIALIZAR VALIDADOR PRE-EJECUCI칍N
        self.pre_execution_validator = PreExecutionValidator()
        self.recent_commands: List[Dict[str, Any]] = []
        print("游댌 Validador pre-ejecuci칩n activado - Comandos ser치n validados antes de ejecutar")
        
        # 游 INICIALIZAR SISTEMA DE APRENDIZAJE
        self.learning_system = LearningSystem()
        print("游 Sistema de aprendizaje autom치tico activado - Mejorar치 basado en errores")
        
        # 游댌 INICIALIZAR DETECTOR DE AMBIG칖EDAD AVANZADO
        self.ambiguity_detector = AmbiguityDetector(self.learning_system)
        print("游댌 Detector de ambig칲edad avanzado activado - An치lisis inteligente de comandos confusos")
        
        # 游꿢 INICIALIZAR CALCULADORA DE CONFIANZA DIN츼MICO
        self.confidence_calculator = DynamicConfidenceCalculator(self.learning_system)
        print("游꿢 Sistema de confianza din치mico activado - C치lculo inteligente de confianza")
            
        # 游꿢 PROMPT SIMPLIFICADO - QUE OLLAMA DECIDA TODO + GROK (CON MEJORAS AUTOM츼TICAS)
        base_system_prompt = """Eres un detector de comandos para la asistente virtual Roxy.

REGLA PRINCIPAL: Responde SIEMPRE en formato JSON v치lido.

CATEGOR칈AS:
1. "app" - Abrir/cerrar aplicaciones
2. "music" - M칰sica, canciones, reproducci칩n
3. "content" - Videos, anime, series, pel칤culas
4. "conversation" - Preguntas, charla normal

NUEVA FUNCIONALIDAD - GROK:
Si el usuario menciona algo espec칤fico que no reconoces completamente (anime, series, juegos, artistas poco conocidos, etc.), 
puedes usar "needs_grok": true para que se consulte informaci칩n externa.

EJEMPLOS DE RESPUESTA:

Input: "abre youtube"
{"category": "app", "action": "open_app", "target": "youtube", "confidence": 0.9, "execution_data": {"app_name": "youtube"}}

Input: "pon m칰sica de bad bunny"  
{"category": "music", "action": "search_music", "target": "bad bunny", "confidence": 0.9, "execution_data": {"search_query": "bad bunny", "platform": "spotify"}}

Input: "pon el opening de dandadan"
{"category": "music", "action": "search_music", "target": "dandadan opening", "confidence": 0.7, "execution_data": {"search_query": "dandadan opening", "platform": "youtube"}, "needs_grok": true, "grok_query": "쯈u칠 es Dandadan y cu치l es el nombre de su opening/canci칩n de apertura?"}

Input: "inicia dj autom치tico"
{"category": "music", "action": "start_auto_dj", "target": null, "confidence": 0.9, "execution_data": {"mood": "auto", "duration": 0}}

Input: "pon el dj en autom치tico y sigue poniendo canciones de creepy nuts"
{"category": "music", "action": "start_auto_dj", "target": "Creepy Nuts", "confidence": 0.9, "execution_data": {"mood": "auto", "artist": "Creepy Nuts", "duration": 0}}

Input: "dj autom치tico con m칰sica de rock"
{"category": "music", "action": "start_auto_dj", "target": "rock", "confidence": 0.9, "execution_data": {"mood": "auto", "genre": "rock", "duration": 0}}

Input: "para el dj"
{"category": "music", "action": "stop_auto_dj", "target": null, "confidence": 0.9, "execution_data": {}}

Input: "quiero ver ese anime de los demonios que sali칩 este a침o"
{"category": "content", "action": "search_content", "target": null, "confidence": 0.6, "execution_data": {"search_query": "anime demonios 2025", "platform": "crunchyroll"}, "needs_grok": true, "grok_query": "쮺u치l es el anime sobre demonios m치s popular que sali칩 en 2025?"}

Input: "쯖칩mo est치s?"
{"category": "conversation", "action": "chat", "target": null, "confidence": 1.0, "execution_data": {}}

IMPORTANTE: 
- SOLO responde con JSON v치lido
- NO agregues explicaciones
- Usa "needs_grok": true cuando necesites informaci칩n espec칤fica que no tienes
- Usa "spotify" para m칰sica conocida, "youtube" para m칰sica de anime/espec칤fica
- Usa "crunchyroll" para anime, "netflix" para series

RESPONDE SOLO JSON:"""
        
        # 游 APLICAR MEJORAS DE APRENDIZAJE AL PROMPT
        self.system_prompt = self.learning_system.apply_improvements_to_prompt(base_system_prompt)
        
        # Verificar disponibilidad de Ollama al inicializar
        self.ollama_available = self._check_ollama_health()
        if not self.ollama_available:
            print("丘멆잺 Ollama no disponible - usando an치lisis de respaldo")
    
    def _check_ollama_health(self) -> bool:
        """Verificar si Ollama est치 disponible y funcionando"""
        if not OLLAMA_AVAILABLE:
            return False
        
        try:
            response = ollama.generate(
                model=self.model,
                prompt="Input: test",
                system=self.system_prompt,
                options={'num_predict': 100, 'temperature': 0}
            )
            
            result_text = response.get('response', '').strip()
            # Verificar que responde con algo que parece JSON completo
            return result_text.startswith('{') and result_text.endswith('}')
                    
        except Exception as e:
            print(f"丘멆잺 Error en health check: {e}")
            return False

    def analyze_command(self, user_input: str, recent_context: Optional[Dict] = None) -> CommandResult:
        """
        Analizar comando del usuario - CON MEMORIA CONVERSACIONAL PERSISTENTE
        
        Args:
            user_input: Texto del usuario
            recent_context: Contexto de conversaci칩n reciente (opcional)
            
        Returns:
            CommandResult: Resultado del an치lisis enriquecido con contexto
        """
        user_input = user_input.strip()
        
        if not user_input:
            result = CommandResult(
                is_command=False,
                command_type="conversation",
                action="chat",
                target=None,
                confidence=0.9,
                natural_response="쮼n qu칠 puedo ayudarte?",
                execution_data={}
            )
            self._save_to_memory(user_input, result, True)
            return result
        
        print(f"游댌 Analizando: '{user_input}'")
        
        # 游댢 CORRECCI칍N AUTOM츼TICA DE COMANDOS
        corrected_input = user_input
        correction_applied = False
        
        if self.command_corrector:
            # Intentar correcci칩n autom치tica
            suggested_correction = self.command_corrector.suggest_best_correction(user_input)
            if suggested_correction and suggested_correction != user_input:
                print(f"游댢 Correcci칩n autom치tica sugerida: '{user_input}'  '{suggested_correction}'")
                corrected_input = suggested_correction
                correction_applied = True
        
        # 游 AN츼LISIS CONTEXTUAL CON MEMORIA
        memory_context = None
        if self.conversation_memory:
            try:
                memory_context = self.conversation_memory.analyze_command_with_context(user_input)
                print(f"游 Contexto de memoria obtenido: {len(memory_context.get('context', {}))} elementos")
                
                # Guardar contexto para el calculador de confianza
                self._last_memory_context = memory_context
                
                # 游눠 MEJORAR INPUT CON PREFERENCIAS
                enhanced_input = self._enhance_input_with_memory(corrected_input, memory_context)
                if enhanced_input != corrected_input:
                    print(f"九 Input mejorado: '{corrected_input}'  '{enhanced_input}'")
                    corrected_input = enhanced_input
                    
            except Exception as e:
                print(f"丘멆잺 Error obteniendo contexto de memoria: {e}")
                memory_context = None
        
        # 游꿢 AN츼LISIS PRINCIPAL CON CONTEXTO
        ollama_result = self._analyze_with_ollama_priority(corrected_input, memory_context, recent_context)
        if ollama_result is not None:
            print(f"九 Ollama decision: {ollama_result.command_type} - {ollama_result.action}")
            
            # 游댌 AN츼LISIS DE AMBIG칖EDAD AVANZADO
            ambiguity_context = {
                'recent_commands': self.recent_commands,
                'memory_context': memory_context,
                'recent_context': recent_context,  # Contexto de conversaci칩n reciente
                'current_media_state': None  # TODO: Integrar con estado actual de reproducci칩n
            }
            
            ambiguity_analysis = self.ambiguity_detector.analyze_ambiguity(
                user_input, ollama_result, ambiguity_context
            )
            
            # 游댌 MANEJAR AMBIG칖EDAD DETECTADA
            if ambiguity_analysis.has_ambiguity:
                print(f"游뚿 Ambig칲edad detectada: score={ambiguity_analysis.ambiguity_score:.2f}, acci칩n={ambiguity_analysis.recommended_action}")
                
                # Decidir c칩mo manejar la ambig칲edad
                if ambiguity_analysis.recommended_action == 'clarify':
                    # Crear resultado que solicita clarificaci칩n
                    clarification_text = "He detectado que tu comando podr칤a tener m칰ltiples interpretaciones:\n\n"
                    clarification_text += "\n".join(ambiguity_analysis.clarification_questions)
                    
                    ollama_result = CommandResult(
                        is_command=False,
                        command_type="conversation",
                        action="request_clarification",
                        target=None,
                        confidence=0.9,
                        natural_response=clarification_text,
                        execution_data={
                            'ambiguity_analysis': ambiguity_analysis,
                            'original_result': ollama_result,
                            'needs_clarification': True
                        }
                    )
                    
                elif ambiguity_analysis.recommended_action == 'suggest_alternatives':
                    # Mostrar alternativas pero proceder con la interpretaci칩n original
                    alternatives_text = "He encontrado estas posibles interpretaciones:\n\n"
                    for i, interp in enumerate(ambiguity_analysis.primary_interpretations[:3], 1):
                        alternatives_text += f"{i}. {interp['description']} (confianza: {interp['confidence']:.2f})\n"
                    alternatives_text += "\nProcediendo con la primera opci칩n. Si no es correcta, d칤melo."
                    
                    ollama_result.natural_response = alternatives_text
                    ollama_result.execution_data['ambiguity_analysis'] = ambiguity_analysis
                    ollama_result.needs_clarification = False  # No bloquear ejecuci칩n
                
                # Para 'execute', continuar normalmente
                
            # Actualizar contexto del detector de ambig칲edad
            self.ambiguity_detector.update_context(user_input, ollama_result)
            
            # 游 APLICAR MEJORAS BASADAS EN MEMORIA
            ollama_result = self._apply_memory_improvements(ollama_result, memory_context)
            
            # Intentar proponer operaciones de memoria para cualquier tipo de input
            if self.memory_bridge:
                try:
                    ops = self.memory_bridge.propose_operations(user_input, ollama_result.natural_response or "")
                    if ops.get('operations'):
                        from personality_config import personality
                        rep = personality.apply_memory_operations(ops['operations'])
                        print(f"游 Memoria actualizada: {rep['applied']}")
                except Exception as e:
                    print(f"丘멆잺 Error aplicando operaciones de memoria: {e}")
            
            # 游댢 REGISTRAR CORRECCI칍N SI FUE APLICADA
            if correction_applied and self.command_corrector:
                # Asumir 칠xito si el comando fue procesado exitosamente
                success = ollama_result.is_command and ollama_result.confidence > 0.5
                self.command_corrector.learn_from_correction(
                    user_input, corrected_input, success, 'auto_correction'
                )
                if success:
                    print(f"九 Correcci칩n autom치tica exitosa registrada")
                else:
                    print(f"丘멆잺 Correcci칩n autom치tica fallida registrada")
            
            # 游 GUARDAR EN MEMORIA CONVERSACIONAL
            self._save_to_memory(user_input, ollama_result, True)
            return ollama_result
        
        # 游댃 FALLBACK CON MEMORIA
        print("丘멆잺 Ollama no disponible - usando fallback con memoria")
        fallback_result = self._fallback_analysis_with_memory(user_input, memory_context)
        self._save_to_memory(user_input, fallback_result, False)
        return fallback_result
    
    def resolve_ambiguity(self, user_input: str, original_analysis: AmbiguityAnalysis, 
                         selection: Optional[int] = None) -> CommandResult:
        """
        游댌 Resolver ambig칲edad basada en la respuesta del usuario
        
        Args:
            user_input: Nueva entrada del usuario para resolver ambig칲edad
            original_analysis: An치lisis de ambig칲edad original
            selection: N칰mero de opci칩n seleccionada (1-based) si aplica
            
        Returns:
            CommandResult: Resultado resuelto
        """
        print(f"游댌 Resolviendo ambig칲edad con input: '{user_input}'")
        
        # Si el usuario seleccion칩 una opci칩n espec칤fica
        if selection and 1 <= selection <= len(original_analysis.primary_interpretations):
            selected_interpretation = original_analysis.primary_interpretations[selection - 1]
            
            result = CommandResult(
                is_command=True,
                command_type=selected_interpretation.get('action', 'unknown'),
                action=selected_interpretation.get('action', 'unknown'),
                target=selected_interpretation.get('target'),
                confidence=selected_interpretation.get('confidence', 0.8),
                natural_response=f"Perfecto, ejecutando: {selected_interpretation.get('description', '')}",
                execution_data=selected_interpretation.get('execution_data', {}),
                needs_clarification=False
            )
            
            print(f"九 Ambig칲edad resuelta por selecci칩n: {result.action} - {result.target}")
            return result
        
        # Analizar la respuesta del usuario para resolver la ambig칲edad
        try:
            # Crear un contexto enriquecido con la informaci칩n de ambig칲edad
            resolution_context = f"""
            Usuario original: {original_analysis.primary_interpretations[0].get('original_input', '')}
            Ambig칲edad detectada: {[signal.description for signal in original_analysis.signals]}
            Opciones disponibles: {[interp['description'] for interp in original_analysis.primary_interpretations]}
            Respuesta del usuario: {user_input}
            """
            
            # Re-analizar con contexto de resoluci칩n
            resolution_result = self._analyze_with_ollama_priority(resolution_context, None, None)
            
            if resolution_result:
                resolution_result.natural_response = f"Entendido, {resolution_result.natural_response or 'ejecutando tu solicitud.'}"
                resolution_result.needs_clarification = False
                print(f"九 Ambig칲edad resuelta por an치lisis: {resolution_result.action} - {resolution_result.target}")
                return resolution_result
            
        except Exception as e:
            print(f"丘멆잺 Error resolviendo ambig칲edad: {e}")
        
        # Fallback: usar la interpretaci칩n m치s probable
        if original_analysis.primary_interpretations:
            best_interpretation = original_analysis.primary_interpretations[0]
            
            result = CommandResult(
                is_command=True,
                command_type=best_interpretation.get('command_type', 'conversation'),
                action=best_interpretation.get('action', 'chat'),
                target=best_interpretation.get('target'),
                confidence=best_interpretation.get('confidence', 0.6),
                natural_response="Usando la interpretaci칩n m치s probable de tu solicitud original.",
                execution_data=best_interpretation.get('execution_data', {}),
                needs_clarification=False
            )
            
            print(f"游댃 Usando interpretaci칩n por defecto: {result.action} - {result.target}")
            return result
        
        # 칔ltimo recurso: conversaci칩n
        return CommandResult(
            is_command=False,
            command_type="conversation",
            action="chat",
            target=None,
            confidence=0.5,
            natural_response="No pude resolver la ambig칲edad. 쯇uedes ser m치s espec칤fico sobre lo que quieres hacer?",
            execution_data={},
            needs_clarification=False
        )
    
    def _analyze_with_ollama_priority(self, user_input: str, memory_context: Optional[Dict[str, Any]] = None, recent_context: Optional[Dict] = None) -> Optional[CommandResult]:
        """
        An치lisis con Ollama como 칔NICA prioridad
        Solo devuelve None si Ollama no est치 disponible o falla
        """
        if not self.ollama_available:
            return None
        
        try:
            print("游 Consultando a Ollama...")
            
            response = ollama.generate(
                model=self.model,
                prompt=f"Input: {user_input}",
                system=self.system_prompt,
                options={
                    'temperature': 0.1,
                    'num_predict': 200,
                }
            )
            
            if not response or not response.get('response', '').strip():
                print("丘멆잺 Respuesta vac칤a de Ollama")
                return None
            
            result_text = response['response'].strip()
            print(f"游 Ollama respuesta: {result_text}")
            
            try:
                # Intentar parsear como JSON
                parsed_result = json.loads(result_text)
                
                # 游댌 VERIFICAR SI NECESITA GROK
                if parsed_result.get('needs_grok', False):
                    print("游깷 Ollama solicit칩 consulta a Grok...")
                    grok_info = self._consult_grok(parsed_result.get('grok_query', ''), user_input)
                    if grok_info:
                        # Re-procesar con la informaci칩n de Grok
                        print("游댃 Re-procesando con informaci칩n de Grok...")
                        return self._reprocess_with_grok_info(user_input, parsed_result, grok_info)
                
                return self._convert_ollama_result_to_command_result(parsed_result, user_input, recent_context)
            except json.JSONDecodeError as e:
                print(f"丘멆잺 Ollama no devolvi칩 JSON v치lido: {e}")
                print(f"丘멆잺 Respuesta fue: {result_text}")
                return None
                
        except Exception as e:
            print(f"丘멆잺 Error consultando Ollama: {e}")
            return None
    
    def _consult_grok(self, grok_query: str, original_input: str) -> Optional[str]:
        """
        Consultar Grok para obtener informaci칩n espec칤fica
        """
        if not self.grok_callback:
            print("丘멆잺 Grok no disponible - callback no configurado")
            return None
        
        try:
            print(f"游깷 Consultando Grok: '{grok_query}'")
            grok_response = self.grok_callback(grok_query)
            
            if grok_response and len(grok_response.strip()) > 10:
                print(f"九 Grok respondi칩: {grok_response[:100]}...")
                return grok_response
            else:
                print("丘멆잺 Grok no pudo responder adecuadamente")
                return None
                
        except Exception as e:
            print(f"仇 Error consultando Grok: {e}")
            return None
    
    def _reprocess_with_grok_info(self, user_input: str, original_result: Dict[str, Any], grok_info: str) -> CommandResult:
        """
        Re-procesar el comando con la informaci칩n obtenida de Grok
        """
        try:
            # Crear prompt mejorado con informaci칩n de Grok
            original_category = original_result.get('category', '')
            original_action = original_result.get('action', '')
            
            # Detectar si es pregunta conversacional
            is_question = any(word in user_input.lower() for word in ['sabes', 'conoces', 'alg칰n', 'algun', 'qu칠', 'que', 'cu치l', 'cual', 'recomienda', 'recomendame', 'sugerencia', 'puedes decirme'])
            
            enhanced_prompt = f"""
Input original: {user_input}

Informaci칩n obtenida de Grok: {grok_info}

AN츼LISIS DE INTENCI칍N:
- 쮼s una PREGUNTA?: {"S칈" if is_question else "NO"}
- Categor칤a original: {original_category}
- Acci칩n original: {original_action}

REGLAS ESTRICTAS:
1. Si el usuario usa palabras como "sabes", "conoces", "alg칰n", "qu칠", "recomienda" -> SIEMPRE usar action: "chat" o "recommend_content"
2. Si es una PREGUNTA sobre recomendaciones -> category: "content", action: "chat"
3. NUNCA uses "search_content" para preguntas conversacionales
4. Solo usa "search_content" si el usuario espec칤ficamente dice "busca", "encuentra", "abre"

Ahora re-analiza y mejora la respuesta JSON manteniendo la intenci칩n conversacional.
"""
            
            print("游댃 Re-consultando Ollama con informaci칩n de Grok...")
            response = ollama.generate(
                model=self.model,
                prompt=enhanced_prompt,
                system=self.system_prompt.replace("RESPONDE SOLO JSON:", "Usa la informaci칩n adicional para mejorar tu respuesta. RESPONDE SOLO JSON:"),
                options={
                    'temperature': 0.1,
                    'num_predict': 200,
                }
            )
            
            if response and response.get('response', '').strip():
                result_text = response['response'].strip()
                print(f"游댃 Ollama mejorado: {result_text}")
                
                try:
                    enhanced_result = json.loads(result_text)
                    command_result = self._convert_ollama_result_to_command_result(enhanced_result, user_input)
                    
                    # 游댢 USAR GROK INFO PARA RESPUESTAS CONVERSACIONALES
                    if command_result.action in ['chat', 'recommend_content', 'suggest_content']:
                        command_result.natural_response = grok_info.strip()
                    
                    # Marcar que se us칩 Grok
                    command_result.grok_used = True
                    command_result.original_query = user_input
                    command_result.grok_query = original_result.get('grok_query')
                    
                    return command_result
                    
                except json.JSONDecodeError:
                    print("丘멆잺 Error parseando respuesta mejorada de Ollama")
                    # Crear resultado conversacional con info de Grok
                    print("游댢 Creando respuesta conversacional con info de Grok")
                    fallback_result = CommandResult(
                        is_command=False,
                        command_type="content",
                        action="chat",
                        target=None,
                        confidence=0.8,
                        natural_response=grok_info.strip(),
                        execution_data={},
                        grok_used=True,
                        original_query=user_input,
                        grok_query=original_result.get('grok_query')
                    )
                    return fallback_result
            
            # Fallback: usar resultado original pero marcando que se intent칩 Grok
            print("丘멆잺 Usando resultado original con informaci칩n parcial de Grok")
            fallback_result = self._convert_ollama_result_to_command_result(original_result, user_input)
            fallback_result.grok_used = True
            fallback_result.original_query = user_input
            
            # 游댢 USAR GROK INFO PARA RESPUESTAS CONVERSACIONALES
            if fallback_result.action in ['chat', 'recommend_content', 'suggest_content']:
                fallback_result.natural_response = grok_info.strip()
            
            # Intentar mejorar el search_query manualmente con info de Grok
            if "search_query" in fallback_result.execution_data:
                improved_query = self._extract_improved_query_from_grok(grok_info, user_input)
                if improved_query:
                    fallback_result.execution_data["search_query"] = improved_query
                    fallback_result.target = improved_query
                    print(f"游댢 Query mejorado manualmente: {improved_query}")
            
            return fallback_result
            
        except Exception as e:
            print(f"仇 Error en reprocesamiento con Grok: {e}")
            # Devolver resultado original
            return self._convert_ollama_result_to_command_result(original_result, user_input)
    
    def _extract_improved_query_from_grok(self, grok_info: str, original_input: str) -> Optional[str]:
        """
        Extraer informaci칩n espec칤fica de la respuesta de Grok para mejorar la b칰squeda
        """
        try:
            grok_lower = grok_info.lower()
            
            # Buscar patrones espec칤ficos en la respuesta de Grok
            patterns = [
                r'opening.*?["\']([^"\']+)["\']',  # "opening llamado 'nombre'"
                r'tema.*?["\']([^"\']+)["\']',     # "tema llamado 'nombre'"
                r'canci칩n.*?["\']([^"\']+)["\']',  # "canci칩n llamada 'nombre'"
                r'se llama ["\']([^"\']+)["\']',   # "se llama 'nombre'"
                r'titulado ["\']([^"\']+)["\']',   # "titulado 'nombre'"
                r'opening:\s*([^\n\.]+)',          # "opening: nombre"
                r't칤tulo:\s*([^\n\.]+)',           # "t칤tulo: nombre"
            ]
            
            for pattern in patterns:
                matches = re.findall(pattern, grok_info, re.IGNORECASE)
                if matches:
                    improved_query = matches[0].strip()
                    if len(improved_query) > 3:  # Filtrar resultados muy cortos
                        return improved_query
            
            # Si no encuentra patrones espec칤ficos, buscar nombres en may칰sculas o entre comillas
            name_patterns = [
                r'["\']([A-Z][^"\']{3,})["\']',   # Nombres entre comillas
                r'\b([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)\b'  # Nombres propios
            ]
            
            for pattern in name_patterns:
                matches = re.findall(pattern, grok_info)
                for match in matches:
                    if len(match) > 3 and match.lower() not in ['dandadan', 'anime', 'manga', 'serie']:
                        return match
            
            return None
            
        except Exception as e:
            print(f"丘멆잺 Error extrayendo query de Grok: {e}")
            return None
    
    def _convert_ollama_result_to_command_result(self, parsed_result: Dict[str, Any], user_input: str, recent_context: Optional[Dict] = None) -> CommandResult:
        """Convertir respuesta de Ollama a CommandResult"""
        category = parsed_result.get('category', 'conversation')
        action = parsed_result.get('action', 'chat')
        target = parsed_result.get('target')
        confidence = parsed_result.get('confidence', 0.8)
        execution_data = parsed_result.get('execution_data', {})
        
        # 游댢 MANEJAR M칔LTIPLES COMANDOS - Tomar el primero
        if isinstance(category, list):
            print(f"丘멆잺 M칰ltiples comandos detectados, tomando el primero: {category}")
            if len(category) > 0:
                first_cmd = category[0]
                if isinstance(first_cmd, dict):
                    # Formato complejo: [{"category": "content", "action": "search_content", ...}]
                    category = first_cmd.get('category', 'conversation')
                    action = first_cmd.get('action', 'chat')
                    target = first_cmd.get('target')
                    confidence = first_cmd.get('confidence', 0.8)
                    execution_data = first_cmd.get('execution_data', {})
                else:
                    # Formato simple: ["app", "music"]
                    category = first_cmd
                    action = parsed_result.get('action', ['chat'])[0] if isinstance(parsed_result.get('action'), list) else parsed_result.get('action', 'chat')
                    target = parsed_result.get('target', [None])[0] if isinstance(parsed_result.get('target'), list) else parsed_result.get('target')
            else:
                category = 'conversation'
                action = 'chat'
        
        # 游댢 NORMALIZAR ACCIONES VARIANTES
        action_mapping = {
            'play_music': 'search_music',
            'play_track': 'search_music', 
            'play_random_music': 'search_music',
            'start_music': 'search_music'
        }
        if action in action_mapping:
            action = action_mapping[action]
        
        # 游댢 MANEJAR LISTAS EN TARGET (m칰ltiples apps)
        if isinstance(target, list) and len(target) > 0:
            print(f"丘멆잺 M칰ltiples targets, tomando el primero: {target}")
            target = str(target[0])
        elif target is not None:
            target = str(target)
        
        # 游댢 ASEGURAR CONFIDENCE ES FLOAT
        try:
            confidence = float(confidence)
        except (TypeError, ValueError):
            confidence = 0.8
        
        # 游댢 MEJORAR EXECUTION_DATA PARA CASOS VAC칈OS
        if not execution_data.get('search_query') and target:
            execution_data['search_query'] = target
        
        # Determinar si es comando
        is_command = category in ['app', 'music', 'content']
        
        # Generar respuesta natural
        natural_response = self._generate_natural_response(category, action, target, user_input)
        
        # Crear resultado inicial con confianza de Ollama
        initial_result = CommandResult(
            is_command=is_command,
            command_type=category,
            action=action,
            target=target,
            confidence=confidence,
            natural_response=natural_response,
            execution_data=execution_data,
            grok_used=False,
            original_query=user_input
        )
        
        # 游꿢 CALCULAR CONFIANZA DIN츼MICAMENTE
        try:
            # Preparar contexto para el calculador de confianza
            confidence_context = {
                'memory_context': getattr(self, '_last_memory_context', {}),
                'recent_commands': self.recent_commands[-10:] if hasattr(self, 'recent_commands') else [],
                'recent_context': recent_context,  # Contexto de conversaci칩n reciente
                'user_input': user_input,
                'parsed_result': parsed_result
            }
            
            # Calcular nueva confianza
            dynamic_confidence = self.confidence_calculator.calculate_confidence(initial_result, confidence_context)
            
            # Actualizar confianza en el resultado
            initial_result.confidence = dynamic_confidence
            
            print(f"游꿢 Confianza actualizada: {confidence:.3f}  {dynamic_confidence:.3f} ({self.confidence_calculator.get_confidence_level(dynamic_confidence)})")
            
        except Exception as e:
            print(f"丘멆잺 Error calculando confianza din치micamente, usando confianza de Ollama: {e}")
        
        return initial_result
    
    def _generate_natural_response(self, category: str, action: str, target: Optional[str], user_input: str) -> str:
        """Generar respuesta natural basada en la categor칤a y acci칩n"""
        if category == "app":
            if action == "open_app" and target:
                return f"Abriendo {target}..."
            elif action == "close_app" and target:
                return f"Cerrando {target}..."
        elif category == "music":
            if target:
                return f"Buscando m칰sica: {target}"
            else:
                return "Iniciando reproducci칩n de m칰sica..."
        elif category == "content":
            if target:
                return f"Buscando contenido: {target}"
            else:
                return "Buscando contenido..."
        
        return "Perfecto, entendido"
    
    def _fallback_analysis(self, user_input: str) -> CommandResult:
        """
        An치lisis de respaldo ULTRA-SIMPLIFICADO
        Solo maneja casos extremadamente obvios
        """
        user_lower = user_input.lower().strip()
        
        # 游댮 SOLO CASOS ULTRA-OBVIOS
        
        # Apps absolutamente claras
        if user_lower.startswith("abre ") and len(user_lower) > 5:
            app_name = user_lower[5:].strip()
            if app_name in ["youtube", "chrome", "spotify", "discord", "whatsapp"]:
                return CommandResult(
                    is_command=True,
                    command_type="app",
                    action="open_app",
                    target=app_name,
                    confidence=0.95,
                    natural_response=f"Abriendo {app_name}...",
                    execution_data={"app_name": app_name},
                    grok_used=False,
                    original_query=user_input
                )
            else:
                # App no reconocida -> conversaci칩n
                return CommandResult(
                    is_command=False,
                    command_type="conversation",
                    action="chat",
                    target=None,
                    confidence=0.8,
                    natural_response="No reconozco esa aplicaci칩n, 쯣uedes ser m치s espec칤fico?",
                    execution_data={},
                    grok_used=False,
                    original_query=user_input
                )
        
        # Comandos incompletos muy vagos
        if user_lower in ["pon", "abre", "pon de"]:
            return CommandResult(
                is_command=False,
                command_type="conversation",
                action="chat",
                target=None,
                confidence=0.9,
                natural_response="쯈u칠 te gustar칤a que ponga o abra?",
                execution_data={},
                grok_used=False,
                original_query=user_input
            )
        
        # Artistas s칰per conocidos
        known_artists = ["bad bunny", "fuerza regida", "peso pluma"]
        for artist in known_artists:
            if artist in user_lower:
                return CommandResult(
                    is_command=True,
                    command_type="music",
                    action="search_music",
                    target=artist,
                    confidence=0.9,
                    natural_response=f"Buscando m칰sica de {artist}",
                    execution_data={"search_query": artist, "platform": "spotify"},
                    grok_used=False,
                    original_query=user_input
                )
        
        # Palabras sueltas que podr칤an ser m칰sica
        if user_lower == "m칰sica":
            return CommandResult(
                is_command=True,
                command_type="music",
                action="search_music",
                target=None,
                confidence=0.8,
                natural_response="Iniciando m칰sica...",
                execution_data={"search_query": "m칰sica", "platform": "spotify"},
                grok_used=False,
                original_query=user_input
            )
        
        # Todo lo dem치s es conversaci칩n (dejar que Ollama decida)
        return CommandResult(
            is_command=False,
            command_type="conversation",
            action="chat",
            target=None,
            confidence=0.7,
            natural_response="Entiendo, 쯘n qu칠 m치s puedo ayudarte?",
            execution_data={},
            grok_used=False,
            original_query=user_input
        )
    
    def _enhance_input_with_memory(self, user_input: str, memory_context: Dict[str, Any]) -> str:
        """
        游 Mejorar input del usuario con informaci칩n de memoria
        """
        if not memory_context or not memory_context.get('suggestions'):
            return user_input
        
        suggestions = memory_context['suggestions']
        enhanced_input = user_input
        
        # 游눠 MEJORAR QUERIES GEN칄RICOS CON PREFERENCIAS
        enhanced_query = suggestions.get('enhanced_query')
        if enhanced_query and enhanced_query != user_input:
            enhanced_input = enhanced_query
        
        # 游꿢 AGREGAR PLATAFORMA PREFERIDA SI NO SE ESPECIFICA
        if not any(platform in user_input.lower() for platform in ['spotify', 'youtube', 'netflix', 'crunchyroll']):
            preferred_platform = suggestions.get('platform_preference')
            if preferred_platform:
                # Solo agregar si es comando de m칰sica/contenido
                if any(word in user_input.lower() for word in ['m칰sica', 'pon', 'canci칩n', 'serie', 'pel칤cula']):
                    print(f"游눠 Sugiriendo plataforma preferida: {preferred_platform}")
        
        return enhanced_input
    
    def _apply_memory_improvements(self, result: CommandResult, memory_context: Optional[Dict[str, Any]]) -> CommandResult:
        """
        游 Aplicar mejoras al resultado basadas en memoria
        """
        if not memory_context:
            return result
        
        context = memory_context.get('context', {})
        suggestions = memory_context.get('suggestions', {})
        
        # 游댃 DETECTAR CONTINUACI칍N DE CONVERSACI칍N
        if context.get('continuation_detection', False):
            recent_context = context.get('recent_context', {})
            if recent_context.get('has_context') and recent_context.get('time_gap', 0) < 300:  # 5 minutos
                print("游댃 Continuaci칩n de conversaci칩n detectada")
                # Mantener contexto de la conversaci칩n anterior
                last_category = recent_context.get('dominant_category')
                if last_category and result.command_type == 'conversation':
                    result.command_type = last_category
                    print(f"游댃 Ajustando categor칤a por contexto: {last_category}")
        
        # 丘멆잺 ADVERTENCIAS DE FALLOS PREVIOS
        failure_warnings = suggestions.get('failure_warnings', [])
        if failure_warnings:
            warning = failure_warnings[0]  # Primera advertencia
            print(f"丘멆잺 Advertencia: comando similar fall칩 {warning['retry_count']} veces")
            result.confidence *= 0.8  # Reducir confianza
            if result.natural_response:
                result.natural_response += f"\n(Nota: comando similar ha fallado antes)"
            else:
                result.natural_response = "(Nota: comando similar ha fallado antes)"
        
        # 游꿢 MEJORAR TARGET CON PREFERENCIAS
        if not result.target or result.target == '':
            preferred_targets = suggestions.get('preferred_targets', [])
            if preferred_targets:
                result.target = preferred_targets[0]
                result.execution_data['search_query'] = preferred_targets[0]
                print(f"游꿢 Target mejorado con preferencia: {preferred_targets[0]}")
        
        # 游늳 MEJORAR PLATAFORMA CON PREFERENCIAS
        platform_preference = suggestions.get('platform_preference')
        if platform_preference and 'platform' in result.execution_data:
            if result.execution_data['platform'] == 'spotify' and platform_preference != 'spotify':
                # Solo cambiar si la preferencia es muy fuerte
                pass  # Mantener por ahora, se puede mejorar
        
        return result
    
    def _fallback_analysis_with_memory(self, user_input: str, memory_context: Optional[Dict[str, Any]]) -> CommandResult:
        """
        游 An치lisis de fallback enriquecido con memoria
        """
        # Usar an치lisis de fallback original como base
        base_result = self._fallback_analysis(user_input)
        
        if not memory_context:
            return base_result
        
        # 游 MEJORAR CON CONTEXTO DE MEMORIA
        context = memory_context.get('context', {})
        suggestions = memory_context.get('suggestions', {})
        
        # 游댌 BUSCAR COMANDOS SIMILARES EXITOSOS
        similar_commands = suggestions.get('similar_commands', [])
        if similar_commands:
            best_match = similar_commands[0]
            print(f"游댌 Comando similar encontrado: {best_match['input']} (similitud: {best_match['similarity']:.2f})")
            
            # Aplicar acci칩n del comando similar si la confianza es baja
            if base_result.confidence < 0.8 and best_match['similarity'] > 0.6:
                base_result.command_type = 'music' if 'music' in best_match['action'] else base_result.command_type
                base_result.action = best_match['action']
                base_result.target = best_match['target']
                base_result.confidence = best_match['similarity'] * 0.8
                base_result.natural_response = f"Bas치ndome en comandos similares: {base_result.natural_response}"
                print(f"游댢 Resultado mejorado con comando similar")
        
        # 游눠 APLICAR PREFERENCIAS
        preferred_targets = suggestions.get('preferred_targets', [])
        if preferred_targets and not base_result.target:
            base_result.target = preferred_targets[0]
            base_result.execution_data['search_query'] = preferred_targets[0]
            base_result.confidence += 0.2
            print(f"游눠 Target aplicado desde preferencias: {preferred_targets[0]}")
        
        return base_result
    
    def _save_to_memory(self, user_input: str, result: CommandResult, ollama_used: bool) -> None:
        """
        游 Guardar interacci칩n en memoria conversacional
        """
        if not self.conversation_memory:
            return
        
        try:
            # Preparar datos del comando
            command_data = {
                'command_type': result.command_type,
                'action': result.action,
                'target': result.target,
                'confidence': result.confidence,
                'execution_data': result.execution_data,
                'grok_used': result.grok_used
            }
            
            # Contexto adicional
            context = {
                'ollama_used': ollama_used,
                'timestamp': time.time(),
                'grok_query': result.grok_query
            }
            
            # Determinar si fue exitoso (ser치 actualizado despu칠s de la ejecuci칩n)
            success = True  # Asumimos 칠xito por ahora, se actualizar치 en execute_command
            
            # Guardar en memoria
            self.conversation_memory.add_conversation_entry(
                user_input=user_input,
                command_result=command_data,
                response=result.natural_response or "",
                success=success,
                context=context
            )
            
        except Exception as e:
            print(f"丘멆잺 Error guardando en memoria: {e}")
    
    def get_memory_stats(self) -> Dict[str, Any]:
        """
        游늵 Obtener estad칤sticas de memoria conversacional
        """
        if not self.conversation_memory:
            return {'error': 'Memoria no disponible'}
        
        try:
            return self.conversation_memory.get_memory_stats()
        except Exception as e:
            return {'error': f'Error obteniendo estad칤sticas: {e}'}
    
    def get_conversation_context(self, last_n: int = 5) -> List[Dict[str, Any]]:
        """
        游닄 Obtener contexto de conversaci칩n reciente
        """
        if not self.conversation_memory:
            return []
        
        try:
            return self.conversation_memory.get_conversation_context(last_n)
        except Exception as e:
            print(f"丘멆잺 Error obteniendo contexto: {e}")
            return []
    
    def get_user_preferences(self, category: Optional[str] = None) -> Dict[str, Any]:
        """
        仇벒잺 Obtener preferencias del usuario
        """
        if not self.conversation_memory:
            return {}
        
        try:
            prefs = self.conversation_memory.get_user_preferences(category)
            return {k: {
                'value': v.value,
                'frequency': v.frequency,
                'confidence': v.confidence,
                'category': v.category,
                'type': v.preference_type
            } for k, v in prefs.items()}
        except Exception as e:
            print(f"丘멆잺 Error obteniendo preferencias: {e}")
            return {}
    
    def _get_system_state(self) -> SystemState:
        """
        游늵 Obtener estado actual del sistema para validaci칩n
        """
        try:
            # Obtener procesos ejecut치ndose
            running_processes = []
            try:
                for proc in psutil.process_iter(['name']):
                    try:
                        running_processes.append(proc.info['name'])
                    except (psutil.NoSuchProcess, psutil.AccessDenied):
                        continue
            except Exception as e:
                print(f"丘멆잺 Error obteniendo procesos: {e}")
                running_processes = []
            
            # Obtener uso de CPU y memoria
            try:
                cpu_usage = psutil.cpu_percent(interval=0.1)
                memory_info = psutil.virtual_memory()
                memory_usage = memory_info.percent
            except Exception as e:
                print(f"丘멆잺 Error obteniendo uso de recursos: {e}")
                cpu_usage = 0.0
                memory_usage = 0.0
            
            # Obtener ventana activa (Windows espec칤fico)
            active_window = None
            try:
                import ctypes
                from ctypes import wintypes
                
                user32 = ctypes.windll.user32
                hwnd = user32.GetForegroundWindow()
                if hwnd:
                    length = user32.GetWindowTextLengthW(hwnd)
                    buff = ctypes.create_unicode_buffer(length + 1)
                    user32.GetWindowTextW(hwnd, buff, length + 1)
                    active_window = buff.value
            except Exception as e:
                print(f"丘멆잺 Error obteniendo ventana activa: {e}")
                active_window = None
            
            # Calcular tiempo de inactividad del usuario (simplificado)
            user_idle_time = 0.0
            try:
                # En Windows, podr칤amos usar GetLastInputInfo, pero por simplicidad usamos 0
                # En una implementaci칩n m치s completa, se implementar칤a correctamente
                user_idle_time = 0.0
            except Exception:
                user_idle_time = 0.0
            
            return SystemState(
                running_processes=running_processes,
                cpu_usage=cpu_usage,
                memory_usage=memory_usage,
                active_window=active_window,
                user_idle_time=user_idle_time,
                current_time=datetime.now()
            )
            
        except Exception as e:
            print(f"仇 Error obteniendo estado del sistema: {e}")
            # Retornar estado por defecto en caso de error
            return SystemState(
                running_processes=[],
                cpu_usage=0.0,
                memory_usage=0.0,
                active_window=None,
                user_idle_time=0.0,
                current_time=datetime.now()
            )
    
    def _add_to_recent_commands(self, result: CommandResult):
        """
        游닇 Agregar comando a la lista de comandos recientes
        """
        try:
            command_entry = {
                'timestamp': time.time(),
                'action': result.action,
                'target': result.target,
                'command_type': result.command_type,
                'confidence': result.confidence
            }
            
            self.recent_commands.append(command_entry)
            
            # Mantener solo los 칰ltimos 50 comandos
            if len(self.recent_commands) > 50:
                self.recent_commands = self.recent_commands[-50:]
                
        except Exception as e:
            print(f"丘멆잺 Error agregando comando reciente: {e}")

    def execute_command(self, result: CommandResult, user_input: str = "") -> bool:
        """
        Ejecutar el comando detectado - CON VALIDACI칍N PRE-EJECUCI칍N Y ACTUALIZACI칍N DE MEMORIA
        
        Args:
            result: Resultado del an치lisis de comando
            user_input: Input original del usuario para contexto
            
        Returns:
            bool: True si se ejecut칩 exitosamente
        """
        # Agregar a comandos recientes
        self._add_to_recent_commands(result)
        
        if not result.is_command:
            # 游 ACTUALIZAR MEMORIA PARA COMANDOS NO EJECUTABLES
            self._update_memory_execution_result(result, True)
            return True
        
        # 游댌 VALIDACI칍N PRE-EJECUCI칍N
        print("游댌 Iniciando validaci칩n pre-ejecuci칩n...")
        
        try:
            # Obtener estado del sistema
            system_state = self._get_system_state()
            
            # Obtener preferencias del usuario
            user_preferences = self.get_user_preferences()
            
            # Crear contexto de validaci칩n
            validation_context = ValidationContext(
                user_input=user_input or result.original_query or "",
                command_result=result,
                system_state=system_state,
                recent_commands=self.recent_commands,
                user_preferences=user_preferences
            )
            
            # Realizar validaci칩n
            validation_result = self.pre_execution_validator.validate_before_execution(validation_context)
            
            # Mostrar resultados de validaci칩n
            self._display_validation_results(validation_result)
            
            # Verificar si debe ejecutarse
            if not validation_result.should_execute:
                print("仇 Comando bloqueado por validaci칩n pre-ejecuci칩n")
                print(f"游늶 Problemas bloqueantes: {', '.join(validation_result.blocking_issues)}")
                
                # 游 ACTUALIZAR MEMORIA CON RESULTADO DE BLOQUEO
                self._update_memory_execution_result(result, False)
                return False
            
            # Aplicar delay si es necesario
            if validation_result.execution_delay > 0:
                print(f"낍 Esperando {validation_result.execution_delay} segundos antes de ejecutar...")
                time.sleep(validation_result.execution_delay)
            
        except Exception as e:
            print(f"丘멆잺 Error en validaci칩n pre-ejecuci칩n: {e}")
            print("游댃 Continuando con ejecuci칩n sin validaci칩n...")
        
        # 游 EJECUTAR COMANDO
        success = False
        try:
            print("游 Ejecutando comando...")
            if result.command_type == "app":
                success = self._execute_app_command(result)
            elif result.command_type == "music":
                success = self._execute_music_command(result)
            elif result.command_type == "content":
                success = self._execute_content_command(result)
            else:
                print(f"丘멆잺 Tipo de comando no soportado: {result.command_type}")
                success = False
                
        except Exception as e:
            print(f"仇 Error ejecutando comando: {e}")
            success = False
        
        # 游 ACTUALIZAR MEMORIA CON RESULTADO DE EJECUCI칍N
        self._update_memory_execution_result(result, success)
        
        # 游 REGISTRAR EN SISTEMA DE APRENDIZAJE
        user_input_for_learning = user_input or result.original_query or ""
        if success:
            # Registrar 칠xito
            self.learning_system.record_success(user_input_for_learning, result)
        else:
            # Registrar fallo
            intended_action = f"{result.action} {result.target or ''}"
            actual_result = "execution_failed"
            error_category = "execution"
            
            # Determinar categor칤a de error m치s espec칤fica
            if not result.is_command:
                error_category = "parsing"
            elif result.confidence < 0.5:
                error_category = "misinterpretation"
            elif hasattr(validation_result, 'should_execute') and not validation_result.should_execute:
                error_category = "validation"
            
            context = {
                'command_type': result.command_type,
                'confidence': result.confidence,
                'validation_issues': getattr(validation_result, 'blocking_issues', []) if 'validation_result' in locals() else []
            }
            
            self.learning_system.record_failure(
                user_input=user_input_for_learning,
                intended_action=intended_action,
                actual_result=actual_result,
                command_type=result.command_type,
                confidence=result.confidence,
                error_category=error_category,
                context=context
            )
        
        return success
    
    def refresh_prompt_with_learning(self):
        """
        游 Actualizar el system_prompt con nuevas mejoras de aprendizaje
        """
        try:
            # Obtener prompt base original
            base_system_prompt = """Eres un detector de comandos para la asistente virtual Roxy.

REGLA PRINCIPAL: Responde SIEMPRE en formato JSON v치lido.

CATEGOR칈AS:
1. "app" - Abrir/cerrar aplicaciones
2. "music" - M칰sica, canciones, reproducci칩n
3. "content" - Videos, anime, series, pel칤culas
4. "conversation" - Preguntas, charla normal

NUEVA FUNCIONALIDAD - GROK:
Si el usuario menciona algo espec칤fico que no reconoces completamente (anime, series, juegos, artistas poco conocidos, etc.), 
puedes usar "needs_grok": true para que se consulte informaci칩n externa.

EJEMPLOS DE RESPUESTA:

Input: "abre youtube"
{"category": "app", "action": "open_app", "target": "youtube", "confidence": 0.9, "execution_data": {"app_name": "youtube"}}

Input: "pon m칰sica de bad bunny"  
{"category": "music", "action": "search_music", "target": "bad bunny", "confidence": 0.9, "execution_data": {"search_query": "bad bunny", "platform": "spotify"}}

Input: "pon el opening de dandadan"
{"category": "music", "action": "search_music", "target": "dandadan opening", "confidence": 0.7, "execution_data": {"search_query": "dandadan opening", "platform": "youtube"}, "needs_grok": true, "grok_query": "쯈u칠 es Dandadan y cu치l es el nombre de su opening/canci칩n de apertura?"}

Input: "inicia dj autom치tico"
{"category": "music", "action": "start_auto_dj", "target": null, "confidence": 0.9, "execution_data": {"mood": "auto", "duration": 0}}

Input: "pon el dj en autom치tico y sigue poniendo canciones de creepy nuts"
{"category": "music", "action": "start_auto_dj", "target": "Creepy Nuts", "confidence": 0.9, "execution_data": {"mood": "auto", "artist": "Creepy Nuts", "duration": 0}}

Input: "dj autom치tico con m칰sica de rock"
{"category": "music", "action": "start_auto_dj", "target": "rock", "confidence": 0.9, "execution_data": {"mood": "auto", "genre": "rock", "duration": 0}}

Input: "para el dj"
{"category": "music", "action": "stop_auto_dj", "target": null, "confidence": 0.9, "execution_data": {}}

Input: "quiero ver ese anime de los demonios que sali칩 este a침o"
{"category": "content", "action": "search_content", "target": null, "confidence": 0.6, "execution_data": {"search_query": "anime demonios 2025", "platform": "crunchyroll"}, "needs_grok": true, "grok_query": "쮺u치l es el anime sobre demonios m치s popular que sali칩 en 2025?"}

Input: "쯖칩mo est치s?"
{"category": "conversation", "action": "chat", "target": null, "confidence": 1.0, "execution_data": {}}

IMPORTANTE: 
- SOLO responde con JSON v치lido
- NO agregues explicaciones
- Usa "needs_grok": true cuando necesites informaci칩n espec칤fica que no tienes
- Usa "spotify" para m칰sica conocida, "youtube" para m칰sica de anime/espec칤fica
- Usa "crunchyroll" para anime, "netflix" para series

RESPONDE SOLO JSON:"""
            
            # Aplicar mejoras de aprendizaje
            improved_prompt = self.learning_system.apply_improvements_to_prompt(base_system_prompt)
            
            if improved_prompt != self.system_prompt:
                self.system_prompt = improved_prompt
                print("游 Prompt actualizado con nuevas mejoras de aprendizaje")
                return True
            else:
                print("游닇 No hay nuevas mejoras de aprendizaje para aplicar")
                return False
                
        except Exception as e:
            print(f"丘멆잺 Error actualizando prompt con aprendizaje: {e}")
            return False
    
    def get_learning_stats(self) -> Dict[str, Any]:
        """
        游늵 Obtener estad칤sticas del sistema de aprendizaje
        """
        try:
            analysis = self.learning_system._analyze_failure_patterns()
            return {
                'total_failures': len(self.learning_system.failure_patterns),
                'total_successes': len(self.learning_system.success_patterns),
                'recent_failures': analysis.get('recent_count', 0),
                'improvements_applied': len(self.learning_system.improvement_history),
                'error_categories': {k: len(v) for k, v in analysis.get('error_categories', {}).items()},
                'command_type_issues': {k: len(v) for k, v in analysis.get('command_types', {}).items()}
            }
        except Exception as e:
            print(f"丘멆잺 Error obteniendo estad칤sticas de aprendizaje: {e}")
            return {}
    
    def _display_validation_results(self, validation_result: ValidationResult):
        """
        游늶 Mostrar resultados de validaci칩n de manera organizada
        """
        print(f"游늵 Resultado de validaci칩n:")
        print(f"   九 Ejecutar: {'S칤' if validation_result.should_execute else 'No'}")
        print(f"   游꿢 Confianza: {validation_result.confidence_score:.2f}")
        
        if validation_result.warnings:
            print(f"   丘멆잺 Advertencias:")
            for warning in validation_result.warnings:
                print(f"       {warning}")
        
        if validation_result.blocking_issues:
            print(f"   仇 Problemas bloqueantes:")
            for issue in validation_result.blocking_issues:
                print(f"       {issue}")
        
        if validation_result.recommendations:
            print(f"   游눠 Recomendaciones:")
            for rec in validation_result.recommendations:
                print(f"       {rec}")
        
        if validation_result.execution_delay > 0:
            print(f"   낍 Delay de ejecuci칩n: {validation_result.execution_delay}s")
    
    def get_validation_stats(self) -> Dict[str, Any]:
        """
        游늵 Obtener estad칤sticas del validador pre-ejecuci칩n
        """
        try:
            return self.pre_execution_validator.get_validation_stats()
        except Exception as e:
            return {'error': f'Error obteniendo estad칤sticas de validaci칩n: {e}'}
    
    def configure_validation_thresholds(self, thresholds: Dict[str, Any]) -> bool:
        """
        丘뙖잺 Configurar umbrales del validador
        
        Args:
            thresholds: Diccionario con nuevos umbrales
            
        Returns:
            bool: True si se configur칩 exitosamente
        """
        try:
            for key, value in thresholds.items():
                if key in self.pre_execution_validator.system_thresholds:
                    self.pre_execution_validator.system_thresholds[key] = value
                    print(f"丘뙖잺 Umbral actualizado: {key} = {value}")
            return True
        except Exception as e:
            print(f"仇 Error configurando umbrales: {e}")
            return False
    
    def set_quiet_hours(self, start_hour: int, end_hour: int) -> bool:
        """
        游댆 Configurar horas de silencio
        
        Args:
            start_hour: Hora de inicio (0-23)
            end_hour: Hora de fin (0-23)
            
        Returns:
            bool: True si se configur칩 exitosamente
        """
        try:
            if 0 <= start_hour <= 23 and 0 <= end_hour <= 23:
                self.pre_execution_validator.quiet_hours['start'] = start_hour
                self.pre_execution_validator.quiet_hours['end'] = end_hour
                print(f"游댆 Horas de silencio configuradas: {start_hour}:00 - {end_hour}:00")
                return True
            else:
                print("仇 Horas inv치lidas (deben estar entre 0 y 23)")
                return False
        except Exception as e:
            print(f"仇 Error configurando horas de silencio: {e}")
            return False
    
    def _update_memory_execution_result(self, result: CommandResult, success: bool) -> None:
        """
        游 Actualizar memoria con el resultado real de la ejecuci칩n
        """
        if not self.conversation_memory:
            return
        
        try:
            # La memoria ya tiene la entrada, solo necesitamos actualizar el 칠xito
            # Por simplicidad, vamos a agregar una nueva entrada con el resultado actualizado
            # En una implementaci칩n m치s sofisticada, se actualizar칤a la entrada existente
            
            if not success and result.is_command:
                # Solo registrar fallos de comandos que deber칤an haber sido ejecutados
                print(f"游 Registrando fallo de ejecuci칩n en memoria")
                # La memoria ya maneja esto internamente en add_conversation_entry
                
        except Exception as e:
            print(f"丘멆잺 Error actualizando resultado en memoria: {e}")
    
    def _execute_app_command(self, result: CommandResult) -> bool:
        """Ejecutar comando de aplicaci칩n"""
        app_name = result.target or result.execution_data.get('app_name', '')
        
        if not app_name:
            print("丘멆잺 No se especific칩 aplicaci칩n")
            return False
        
        # 游댢 MANEJAR M칔LTIPLES APPS (si qued칩 alguna en execution_data)
        app_names = result.execution_data.get('app_names', [app_name])
        if isinstance(app_names, list) and len(app_names) > 1:
            print(f"游댃 Ejecutando m칰ltiples apps: {app_names}")
            success_count = 0
            for app in app_names:
                if self._execute_single_app(app, result.action):
                    success_count += 1
            return success_count > 0
        else:
            return self._execute_single_app(app_name, result.action)
    
    def _execute_single_app(self, app_name: str, action: str) -> bool:
        """Ejecutar una sola aplicaci칩n"""
        try:
            if action == "open_app":
                if app_name.lower() == "youtube":
                    webbrowser.open("https://youtube.com")
                elif app_name.lower() in ["chrome", "google chrome"]:
                    subprocess.Popen(["start", "chrome"], shell=True)
                elif app_name.lower() == "spotify":
                    subprocess.Popen(["start", "spotify:"], shell=True)
                elif app_name.lower() == "discord":
                    subprocess.Popen(["start", "discord:"], shell=True)
                elif app_name.lower() == "whatsapp":
                    subprocess.Popen(["start", "whatsapp:"], shell=True)
                elif app_name.lower() in ["music", "m칰sica"]:
                    # App gen칠rica de m칰sica -> Spotify
                    subprocess.Popen(["start", "spotify:"], shell=True)
                elif app_name.lower() in ["navegador", "browser"]:
                    # Navegador gen칠rico -> Chrome
                    subprocess.Popen(["start", "chrome"], shell=True)
                elif app_name.lower() == "steam":
                    # Steam: M칰ltiples m칠todos de fallback
                    return self._execute_steam_advanced()
                else:
                    # Intento gen칠rico mejorado con m칰ltiples fallbacks
                    return self._execute_generic_app_advanced(app_name)
                
                print(f"九 Abriendo {app_name}")
                return True
                
            elif action == "close_app":
                # Comando b치sico de cierre
                subprocess.run(f"taskkill /f /im {app_name}.exe", shell=True, capture_output=True)
                print(f"九 Cerrando {app_name}")
                return True
                
        except Exception as e:
            print(f"仇 Error ejecutando app {app_name}: {e}")
            return False
        
        return False
    
    def _execute_steam_advanced(self) -> bool:
        """
        M칠todos avanzados para abrir Steam cuando 'start steam' falla
        """
        steam_paths = [
            # Rutas comunes de instalaci칩n de Steam
            r"C:\Program Files (x86)\Steam\steam.exe",
            r"C:\Program Files\Steam\steam.exe", 
            r"C:\Steam\steam.exe",
            # Ruta del acceso directo encontrada
            r"C:\Users\Shark\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Steam\Steam.lnk"
        ]
        
        print("游꿡 Steam: Probando m칠todos avanzados...")
        
        # M칠todo 1: Protocolo steam://
        try:
            print("游닇 M칠todo 1: Protocolo steam://")
            subprocess.Popen(["start", "steam://"], shell=True)
            print("九 Steam abierto via protocolo steam://")
            return True
        except Exception as e:
            print(f"丘멆잺 Protocolo steam:// fall칩: {e}")
        
        # M칠todo 2: Buscar ejecutable directo
        for steam_path in steam_paths:
            if os.path.exists(steam_path):
                try:
                    print(f"游닇 M칠todo 2: Ejecutable directo - {steam_path}")
                    if steam_path.endswith('.lnk'):
                        # Es un acceso directo, usar start
                        subprocess.Popen(["start", "", steam_path], shell=True)
                    else:
                        # Es un ejecutable, lanzar directamente
                        subprocess.Popen([steam_path])
                    print(f"九 Steam abierto desde: {steam_path}")
                    return True
                except Exception as e:
                    print(f"丘멆잺 Fall칩 {steam_path}: {e}")
                    continue
        
        # M칠todo 3: Buscar en registro de Windows
        try:
            print("游닇 M칠todo 3: B칰squeda en registro de Windows")
            result = subprocess.run(
                ["reg", "query", "HKEY_LOCAL_MACHINE\\SOFTWARE\\Valve\\Steam", "/v", "InstallPath"],
                capture_output=True, text=True, shell=True
            )
            if result.returncode == 0:
                # Extraer la ruta del resultado
                for line in result.stdout.split('\n'):
                    if 'InstallPath' in line and 'REG_SZ' in line:
                        steam_dir = line.split('REG_SZ')[-1].strip()
                        steam_exe = os.path.join(steam_dir, "steam.exe")
                        if os.path.exists(steam_exe):
                            subprocess.Popen([steam_exe])
                            print(f"九 Steam abierto desde registro: {steam_exe}")
                            return True
        except Exception as e:
            print(f"丘멆잺 B칰squeda en registro fall칩: {e}")
        
        # M칠todo 4: Powershell Start-Process
        try:
            print("游닇 M칠todo 4: PowerShell Start-Process")
            ps_command = 'Start-Process "steam://open/main"'
            subprocess.run(["powershell", "-Command", ps_command], shell=True)
            print("九 Steam abierto via PowerShell")
            return True
        except Exception as e:
            print(f"丘멆잺 PowerShell fall칩: {e}")
        
        print("仇 Todos los m칠todos para abrir Steam han fallado")
        return False
    
    def _execute_generic_app_advanced(self, app_name: str) -> bool:
        """
        M칠todo gen칠rico avanzado con exploraci칩n inteligente del sistema
        """
        print(f"游댢 Exploraci칩n inteligente para: {app_name}")
        
        # M칠todo 1: Intento original (r치pido)
        try:
            print(f"游닇 M칠todo 1: start {app_name}")
            subprocess.Popen(["start", app_name], shell=True)
            print(f"九 {app_name} abierto con start")
            return True
        except Exception as e:
            print(f"丘멆잺 start {app_name} fall칩: {e}")
        
        # M칠todo 2: Protocolo URL
        try:
            print(f"游닇 M칠todo 2: protocolo {app_name}://")
            subprocess.Popen(["start", f"{app_name}://"], shell=True)
            print(f"九 {app_name} abierto via protocolo")
            return True
        except Exception as e:
            print(f"丘멆잺 protocolo {app_name}:// fall칩: {e}")
        
        # 游댌 M칄TODO 3: EXPLORACI칍N INTELIGENTE DEL SISTEMA
        found_app = self._intelligent_app_search(app_name)
        if found_app:
            try:
                print(f"游닇 M칠todo 3: Exploraci칩n inteligente - {found_app}")
                if found_app.endswith('.lnk'):
                    subprocess.Popen(["start", "", found_app], shell=True)
                else:
                    subprocess.Popen([found_app])
                print(f"九 {app_name} abierto desde exploraci칩n: {found_app}")
                return True
            except Exception as e:
                print(f"丘멆잺 Exploraci칩n fall칩: {e}")
        
        # M칠todo 4: PowerShell Get-Command
        try:
            print(f"游닇 M칠todo 4: PowerShell Get-Command")
            ps_command = f'Get-Command "{app_name}" -ErrorAction SilentlyContinue | Select-Object -ExpandProperty Source'
            result = subprocess.run(
                ["powershell", "-Command", ps_command],
                capture_output=True, text=True, shell=True
            )
            if result.returncode == 0 and result.stdout.strip():
                app_path = result.stdout.strip()
                subprocess.Popen([app_path])
                print(f"九 {app_name} abierto desde PowerShell: {app_path}")
                return True
        except Exception as e:
            print(f"丘멆잺 PowerShell Get-Command fall칩: {e}")
        
        print(f"仇 No se pudo encontrar {app_name} en el sistema")
        return False
    
    def _intelligent_app_search(self, app_name: str) -> Optional[str]:
        """
        B칰squeda inteligente de aplicaciones en todo el sistema
        """
        print(f"游댌 Explorando sistema para encontrar: {app_name}")
        
        # Lista de ubicaciones comunes donde buscar
        search_locations = [
            # Program Files
            r"C:\Program Files",
            r"C:\Program Files (x86)",
            # Start Menu (usuario actual)
            rf"C:\Users\{os.environ.get('USERNAME', 'Default')}\AppData\Roaming\Microsoft\Windows\Start Menu\Programs",
            # Start Menu (todos los usuarios)
            r"C:\ProgramData\Microsoft\Windows\Start Menu\Programs",
            # Desktop
            rf"C:\Users\{os.environ.get('USERNAME', 'Default')}\Desktop",
            # AppData Local
            rf"C:\Users\{os.environ.get('USERNAME', 'Default')}\AppData\Local",
            # Otras ubicaciones comunes
            r"C:\Games",
            r"D:\Games",
            r"D:\Program Files",
            r"D:\Program Files (x86)"
        ]
        
        # Patrones de b칰squeda (orden de prioridad)
        search_patterns = [
            f"{app_name}.exe",           # Exacto
            f"{app_name}.lnk",           # Acceso directo exacto
            f"{app_name.title()}.exe",   # Con primera letra may칰scula
            f"{app_name.title()}.lnk",   # Acceso directo con may칰scula
            f"{app_name.upper()}.exe",   # Todo en may칰sculas
            f"{app_name.lower()}.exe",   # Todo en min칰sculas
            f"*{app_name}*.exe",         # Que contenga el nombre
            f"*{app_name}*.lnk"          # Acceso directo que contenga el nombre
        ]
        
        for location in search_locations:
            if not os.path.exists(location):
                continue
                
            print(f"涌 Explorando: {location}")
            
            try:
                # B칰squeda recursiva inteligente
                found_path = self._recursive_app_search(location, app_name, search_patterns)
                if found_path:
                    print(f"游꿢 춰Encontrado! {found_path}")
                    return found_path
                    
            except Exception as e:
                print(f"丘멆잺 Error explorando {location}: {e}")
                continue
        
        # 游댌 B칔SQUEDA ADICIONAL: Usar where de Windows (m치s r치pido)
        try:
            print(f"游닇 B칰squeda adicional con 'where'")
            result = subprocess.run(
                ["where", "/R", "C:\\", f"{app_name}.exe"],
                capture_output=True, text=True, shell=True, timeout=10  # Reducido a 10 segundos
            )
            if result.returncode == 0 and result.stdout.strip():
                found_paths = result.stdout.strip().split('\n')
                for path in found_paths:
                    if os.path.exists(path.strip()):
                        print(f"游꿢 Encontrado con 'where': {path.strip()}")
                        return path.strip()
        except subprocess.TimeoutExpired:
            print(f"낋 B칰squeda con 'where' tard칩 demasiado, continuando...")
        except Exception as e:
            print(f"丘멆잺 B칰squeda con 'where' fall칩: {e}")
        
        print(f"仇 No se encontr칩 {app_name} en ninguna ubicaci칩n")
        return None
    
    def _recursive_app_search(self, base_path: str, app_name: str, patterns: List[str], max_depth: int = 3) -> Optional[str]:
        """
        B칰squeda recursiva con l칤mite de profundidad para evitar b칰squedas muy largas
        """
        if max_depth <= 0:
            return None
            
        try:
            # Buscar en el directorio actual
            for pattern in patterns:
                if '*' in pattern:
                    # Usar glob para patrones con wildcard
                    import glob
                    search_pattern = os.path.join(base_path, pattern)
                    matches = glob.glob(search_pattern)
                    if matches:
                        # Priorizar ejecutables sobre accesos directos
                        exe_matches = [m for m in matches if m.endswith('.exe')]
                        if exe_matches:
                            return exe_matches[0]
                        return matches[0]
                else:
                    # B칰squeda exacta
                    full_path = os.path.join(base_path, pattern)
                    if os.path.exists(full_path):
                        return full_path
            
            # Buscar en subdirectorios (solo un nivel para app_name espec칤fico)
            app_folder_path = os.path.join(base_path, app_name)
            if os.path.exists(app_folder_path):
                result = self._recursive_app_search(app_folder_path, app_name, patterns, max_depth - 1)
                if result:
                    return result
            
            # Buscar en subdirectorios con nombre similar
            app_folder_title = os.path.join(base_path, app_name.title())
            if os.path.exists(app_folder_title):
                result = self._recursive_app_search(app_folder_title, app_name, patterns, max_depth - 1)
                if result:
                    return result
                    
        except Exception as e:
            print(f"丘멆잺 Error en b칰squeda recursiva {base_path}: {e}")
        
        return None
    
    def _execute_music_command(self, result: CommandResult) -> bool:
        """Ejecutar comando musical - PRIORIDAD: API > Controlador Avanzado > Fallback"""
        
        # 游뱄 COMANDOS DEL DJ AUTOM츼TICO
        if result.action in ["start_auto_dj", "stop_auto_dj", "change_dj_mood"]:
            return self._execute_auto_dj_command(result)
        
        search_query = result.execution_data.get('search_query', result.target or '')
        platform = result.execution_data.get('platform', 'spotify')
        
        # 游 SELECCI칍N INTELIGENTE PERSONALIZADA
        if self.intelligent_selector and (not search_query or search_query.strip() == '' or search_query.lower() in ['m칰sica', 'music', 'pon m칰sica']):
            print(f"游 Usando selecci칩n inteligente personalizada...")
            try:
                recommendation = self.intelligent_selector.get_recommended_track(search_query, 'general')
                if recommendation and recommendation.get('track'):
                    track = recommendation['track']
                    print(f"九 Recomendaci칩n inteligente: {track.get('artist', 'N/A')} - {track.get('name', 'N/A')}")
                    print(f"游닇 Raz칩n: {recommendation.get('reason', 'Selecci칩n personalizada')}")
                    
                    # Reproducir la recomendaci칩n DIRECTAMENTE por URI
                    track_uri = track.get('uri', '')
                    if track_uri and self.spotify_controller_unified:
                        print(f"游꿢 Reproduciendo canci칩n espec칤fica por URI: {track_uri}")
                        result_api = self.spotify_controller_unified.play_track_by_uri(track_uri, track)
                        if result_api and result_api.get('success'):
                            print(f"九 Reproducci칩n inteligente exitosa! M칠todo: {result_api.get('method')}")
                            return True
                        else:
                            print(f"丘멆잺 Fallo reproduciendo recomendaci칩n por URI: {result_api.get('error', 'Error desconocido')}")
                            print(f"游댃 Continuando con m칠todos normales...")
            except Exception as e:
                print(f"仇 Error en selecci칩n inteligente: {e}")
                print(f"游댃 Continuando con selecci칩n normal...")
        
        # 游댢 MANEJAR QUERIES VAC칈OS - usar t칠rminos por defecto
        if not search_query or search_query.strip() == '':
            # Si no hay query espec칤fico, usar algo gen칠rico
            fallback_queries = ['m칰sica', 'random music', 'top hits']
            search_query = fallback_queries[0]
            print(f"游꿧 Sin query espec칤fico, usando: '{search_query}'")
        
        # 游꿢 PRIORIDAD 1: SPOTIFY UNIFICADO (M츼S CONFIABLE)
        if platform.lower() == 'spotify' and self.spotify_controller_unified and SPOTIFY_API_AVAILABLE:
            print(f"游 Usando Spotify Unificado (PRIORITARIO) para: '{search_query}'")
            try:
                result_api = self.spotify_controller_unified.play_music_advanced(search_query)
                if result_api['success']:
                    print(f"九 Reproducci칩n exitosa via Spotify Unificado!")
                    return True
                else:
                    print(f"丘멆잺 Spotify Unificado fall칩: {result_api.get('error', 'Error desconocido')}")
                    print(f"涌 Continuando con m칠todos alternativos...")
            except Exception as e:
                print(f"仇 Error con Spotify Unificado: {e}")
                print(f"游댃 Continuando con m칠todos alternativos...")
        
        # 游꿢 PRIORIDAD 2: CONTROLADOR AVANZADO (AUTOMATIZACI칍N)
        if self.music_controller and ADVANCED_MUSIC_AVAILABLE:
            print(f"游꿧 Usando controlador avanzado para: '{search_query}' en {platform}")
            return self.music_controller.play_music_advanced(search_query, platform)
        
        # 游댃 FALLBACK: M칠todos originales
        try:
            if platform == "spotify":
                # 游꿧 NUEVA FUNCIONALIDAD: Intentar reproducir directamente en Spotify
                spotify_success = self._try_spotify_direct_play(search_query)
                if spotify_success:
                    print(f"游꿧 REPRODUCIENDO directamente: '{search_query}' en Spotify")
                    return True
                
                # Fallback: Abrir b칰squeda en Spotify web
                encoded_query = search_query.replace(' ', '%20')
                url = f"https://open.spotify.com/search/{encoded_query}"
                webbrowser.open(url)
                print(f"九 Buscando '{search_query}' en Spotify")
                return True
            elif platform == "youtube":
                # 游꿧 NUEVA FUNCIONALIDAD: Intentar reproducir directamente en YouTube
                youtube_success = self._try_youtube_direct_play(search_query)
                if youtube_success:
                    print(f"游꿧 REPRODUCIENDO directamente: '{search_query}' en YouTube")
                    return True
                
                # Fallback: Abrir b칰squeda en YouTube
                encoded_query = search_query.replace(' ', '+')
                url = f"https://www.youtube.com/results?search_query={encoded_query}"
                webbrowser.open(url)
                print(f"九 Buscando '{search_query}' en YouTube")
                return True
                
        except Exception as e:
            print(f"仇 Error ejecutando m칰sica: {e}")
            return False
        
        return False
    
    def _execute_auto_dj_command(self, result: CommandResult) -> bool:
        """Ejecutar comando del DJ autom치tico"""
        action = result.action
        
        # Necesitamos acceso al bot principal a trav칠s del callback
        if not hasattr(self, 'grok_callback') or not self.grok_callback:
            print("丘멆잺 No se puede ejecutar comandos de DJ autom치tico sin acceso al bot principal")
            return False
        
        try:
            # El grok_callback nos da acceso al bot principal
            bot_instance = self.grok_callback.__self__ if hasattr(self.grok_callback, '__self__') else None
            
            if not bot_instance:
                print("丘멆잺 No se pudo obtener instancia del bot")
                return False
            
            if action == "start_auto_dj":
                mood = result.execution_data.get('mood', 'auto')
                duration = result.execution_data.get('duration', 0)
                artist = result.execution_data.get('artist')
                genre = result.execution_data.get('genre')
                
                # Priorizar artista sobre mood gen칠rico
                if artist:
                    response = bot_instance.start_auto_dj_with_artist(artist, duration)
                    print(f"游뱄 {response}")
                elif genre:
                    response = bot_instance.start_auto_dj_with_genre(genre, duration)  
                    print(f"游뱄 {response}")
                else:
                    response = bot_instance.start_auto_dj(mood, duration)
                    print(f"游뱄 {response}")
                return True
                
            elif action == "stop_auto_dj":
                response = bot_instance.stop_auto_dj()
                print(f"낓勇 {response}")
                return True
                
            elif action == "change_dj_mood":
                new_mood = result.execution_data.get('mood', result.target or '')
                if not new_mood:
                    print("丘멆잺 No se especific칩 mood para cambiar")
                    return False
                
                response = bot_instance.change_auto_dj_mood(new_mood)
                print(f"游꿠 {response}")
                return True
            
            return False
            
        except Exception as e:
            print(f"仇 Error ejecutando comando de DJ autom치tico: {e}")
            return False
    
    def _try_spotify_direct_play(self, search_query: str) -> bool:
        """游꿧 Intentar reproducir directamente en Spotify usando protocolo spotify:"""
        try:
            # Formatear query para protocolo Spotify
            clean_query = search_query.replace(' ', '%20')
            spotify_uri = f"spotify:search:{clean_query}"
            
            # Intentar abrir directamente en la app de Spotify
            subprocess.Popen(["start", spotify_uri], shell=True)
            
            # Tambi칠n intentar con protocolo web para auto-play
            time.sleep(1)
            play_url = f"https://open.spotify.com/search/{clean_query}?si=autoplay"
            webbrowser.open(play_url)
            
            return True
        except Exception as e:
            print(f"丘멆잺 Error reproducci칩n directa Spotify: {e}")
            return False
    
    def _try_youtube_direct_play(self, search_query: str) -> bool:
        """游꿧 Intentar reproducir directamente en YouTube"""
        try:
            # Buscar y reproducir el primer resultado autom치ticamente
            clean_query = search_query.replace(' ', '+')
            # URL especial que busca y reproduce autom치ticamente el primer resultado
            autoplay_url = f"https://www.youtube.com/results?search_query={clean_query}&autoplay=1"
            webbrowser.open(autoplay_url)
            
            return True
        except Exception as e:
            print(f"丘멆잺 Error reproducci칩n directa YouTube: {e}")
            return False
    
    def _execute_content_command(self, result: CommandResult) -> bool:
        """Ejecutar comando de contenido"""
        # 游댢 VERIFICAR SI ES ACCI칍N CONVERSACIONAL O PREGUNTA
        if result.action in ['chat', 'recommend_content', 'suggest_content']:
            print(f"游눫 Acci칩n conversacional detectada: {result.action} - No ejecutando b칰squeda")
            return True  # No ejecutar nada, solo conversaci칩n
        
        # 游댢 DETECTAR PREGUNTAS QUE LLEGARON COMO search_content PERO SON CONVERSACIONALES
        if result.action == 'search_content':
            query_to_check = result.original_query or result.grok_query or ''
            is_question = any(word in query_to_check.lower() for word in 
                            ['sabes', 'conoces', 'alg칰n', 'algun', 'qu칠', 'que', 'cu치l', 'cual', 'recomienda', 'recomendame'])
            if is_question:
                print(f"游눫 Pregunta detectada en search_content - Tratando como conversacional")
                return True  # No ejecutar b칰squeda, mantener conversaci칩n
        
        search_query = result.execution_data.get('search_query', result.target or '')
        platform = result.execution_data.get('platform', 'netflix')
        
        # 游댢 MANEJAR QUERIES VAC칈OS - usar t칠rminos por defecto
        if not search_query or search_query.strip() == '':
            # Si no hay query espec칤fico, usar algo gen칠rico basado en platform
            if platform.lower() == 'crunchyroll':
                search_query = 'anime'
            else:
                search_query = 'entretenimiento'
            print(f"游닠 Sin query espec칤fico, usando: '{search_query}'")
        
        try:
            # 游댢 CORREGIR: Comparar en min칰sculas para evitar problemas de case
            platform_lower = platform.lower()
            
            if platform_lower == "netflix":
                encoded_query = search_query.replace(' ', '%20')
                url = f"https://www.netflix.com/search?q={encoded_query}"
                webbrowser.open(url)
                print(f"九 Buscando '{search_query}' en Netflix")
                return True
            elif platform_lower == "crunchyroll":
                encoded_query = search_query.replace(' ', '%20')
                url = f"https://www.crunchyroll.com/search?q={encoded_query}"
                webbrowser.open(url)
                print(f"九 Buscando '{search_query}' en Crunchyroll")
                return True
            elif platform_lower == "disney" or platform_lower == "disney+":
                encoded_query = search_query.replace(' ', '%20')
                url = f"https://www.disneyplus.com/search?q={encoded_query}"
                webbrowser.open(url)
                print(f"九 Buscando '{search_query}' en Disney+")
                return True
            else:
                print(f"丘멆잺 Plataforma no soportada: '{platform}' - usando Netflix como fallback")
                encoded_query = search_query.replace(' ', '%20')
                url = f"https://www.netflix.com/search?q={encoded_query}"
                webbrowser.open(url)
                print(f"九 Buscando '{search_query}' en Netflix (fallback)")
                return True
                
        except Exception as e:
            print(f"仇 Error ejecutando contenido: {e}")
            return False
    
    def get_correction_suggestions(self, user_input: str, context: Optional[Dict] = None) -> List[Dict]:
        """
        游댢 Obtener sugerencias de correcci칩n para un comando
        
        Args:
            user_input: Texto del usuario
            context: Contexto adicional
            
        Returns:
            Lista de sugerencias de correcci칩n
        """
        if not self.command_corrector:
            return []
        
        suggestions = self.command_corrector.analyze_and_correct(user_input, context)
        return [
            {
                'original': s.original_text,
                'corrected': s.corrected_text,
                'type': s.correction_type,
                'confidence': s.confidence,
                'explanation': s.explanation
            }
            for s in suggestions
        ]
    
    def get_correction_stats(self) -> Dict:
        """
        游늵 Obtener estad칤sticas del sistema de correcci칩n autom치tica
        
        Returns:
            Diccionario con estad칤sticas de correcci칩n
        """
        if not self.command_corrector:
            return {
                'available': False,
                'message': 'Corrector autom치tico no disponible'
            }
        
        stats = self.command_corrector.get_correction_stats()
        stats['available'] = True
        return stats
    
    def apply_manual_correction(self, original: str, corrected: str, was_successful: bool) -> bool:
        """
        游댢 Aplicar correcci칩n manual y registrarla para aprendizaje
        
        Args:
            original: Texto original
            corrected: Texto corregido
            was_successful: Si la correcci칩n fue exitosa
            
        Returns:
            True si se registr칩 correctamente
        """
        if not self.command_corrector:
            return False
        
        try:
            self.command_corrector.learn_from_correction(
                original, corrected, was_successful, 'manual_correction'
            )
            print(f"九 Correcci칩n manual registrada: '{original}'  '{corrected}'")
            return True
        except Exception as e:
            print(f"丘멆잺 Error registrando correcci칩n manual: {e}")
            return False


# Funci칩n de ayuda para testing
def test_detector():
    """Funci칩n de prueba para el detector"""
    detector = UnifiedCommandDetector()
    
    test_cases = [
        "pon m칰sica de bad bunny",
        "abre youtube", 
        "quiero ver breaking bad",
        "쯖칩mo est치s?",
        "pon el opening de demon slayer"
    ]
    
    for test in test_cases:
        print(f"\n游빍 Probando: '{test}'")
        result = detector.analyze_command(test)
        print(f"游늵 Resultado: {result.command_type} - {result.action} - {result.target}")
        print(f"游눫 Respuesta: {result.natural_response}")
        
        # Probar ejecuci칩n tambi칠n (con validaci칩n)
        if result.is_command:
            print(f"游꿢 Ejecutando comando con validaci칩n...")
            success = detector.execute_command(result, test)
            print(f"九 Ejecutado: {success}")
            
            # Mostrar estad칤sticas de validaci칩n
            stats = detector.get_validation_stats()
            if stats.get('total_validations', 0) > 0:
                print(f"游늵 Estad칤sticas de validaci칩n:")
                print(f"   Total validaciones: {stats['total_validations']}")
                print(f"   Ejecutados: {stats['executed']}")
                print(f"   Bloqueados: {stats['blocked']}")
                print(f"   Tasa de ejecuci칩n: {stats['execution_rate']:.2%}")
                print(f"   Confianza promedio: {stats['average_confidence']:.2f}")
        else:
            print(f"游눫 Comando conversacional - no requiere ejecuci칩n")

def test_validation_system():
    """Funci칩n de prueba espec칤fica para el sistema de validaci칩n"""
    print("游빍 TESTING SISTEMA DE VALIDACI칍N PRE-EJECUCI칍N")
    print("=" * 60)
    
    detector = UnifiedCommandDetector()
    
    # Configurar umbrales m치s estrictos para testing
    test_thresholds = {
        'cpu_usage_max': 50.0,    # CPU m치s estricto
        'memory_usage_max': 70.0, # RAM m치s estricto
        'command_frequency_max': 3 # Frecuencia m치s estricta
    }
    detector.configure_validation_thresholds(test_thresholds)
    print(f"丘뙖잺 Umbrales configurados para testing: {test_thresholds}")
    
    # Configurar horas de silencio para testing
    current_hour = datetime.now().hour
    detector.set_quiet_hours(current_hour, (current_hour + 1) % 24)
    print(f"游댆 Horas de silencio configuradas para testing")
    
    # Casos de prueba con diferentes escenarios de validaci칩n
    test_scenarios = [
        {
            'input': 'abre steam',
            'description': 'Comando de aplicaci칩n - deber칤a validar conflictos y apps ejecut치ndose'
        },
        {
            'input': 'pon m칰sica de bad bunny',
            'description': 'Comando de m칰sica - deber칤a validar horas de silencio y apps de m칰sica'
        },
        {
            'input': 'abre youtube',
            'description': 'Comando repetido - deber칤a detectar si ya est치 ejecut치ndose'
        },
        {
            'input': 'quiero ver breaking bad',
            'description': 'Comando de contenido - deber칤a validar hora apropiada'
        },
        {
            'input': '쯖칩mo est치s?',
            'description': 'Comando conversacional - no deber칤a requerir validaci칩n'
        }
    ]
    
    for i, scenario in enumerate(test_scenarios, 1):
        print(f"\n{'='*20} ESCENARIO {i} {'='*20}")
        print(f"游닇 Descripci칩n: {scenario['description']}")
        print(f"游빍 Input: '{scenario['input']}'")
        
        # Analizar comando
        result = detector.analyze_command(scenario['input'])
        print(f"游늵 An치lisis: {result.command_type} - {result.action} - {result.target}")
        
        # Ejecutar con validaci칩n (esto mostrar치 todos los detalles de validaci칩n)
        if result.is_command:
            success = detector.execute_command(result, scenario['input'])
            print(f"游꿢 Resultado final: {'九 Ejecutado' if success else '仇 Bloqueado'}")
        else:
            print(f"游눫 Comando conversacional - sin validaci칩n requerida")
        
        # Peque침a pausa entre escenarios
        time.sleep(1)
    
    # Mostrar estad칤sticas finales
    print(f"\n{'='*20} ESTAD칈STICAS FINALES {'='*20}")
    stats = detector.get_validation_stats()
    if stats.get('total_validations', 0) > 0:
        print(f"游늵 Total de validaciones realizadas: {stats['total_validations']}")
        print(f"九 Comandos ejecutados: {stats['executed']}")
        print(f"仇 Comandos bloqueados: {stats['blocked']}")
        print(f"游늳 Tasa de ejecuci칩n: {stats['execution_rate']:.2%}")
        print(f"游꿢 Confianza promedio: {stats['average_confidence']:.2f}")
        
        print(f"\n游댌 칔ltimas validaciones:")
        for validation in stats.get('recent_validations', [])[-3:]:
            timestamp = datetime.fromtimestamp(validation['timestamp']).strftime('%H:%M:%S')
            status = "九" if validation['should_execute'] else "仇"
            print(f"   {status} {timestamp} - {validation['action']} ({validation['confidence_score']:.2f})")
    else:
        print("游늵 No se realizaron validaciones durante las pruebas")


if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == "validation":
        test_validation_system()
    elif len(sys.argv) > 1 and sys.argv[1] == "correction":
        # Demo del sistema de correcci칩n
        detector = UnifiedCommandDetector()
        test_commands = [
            "abre crome",
            "reproduce musica",
            "pon el m칰sica",
            "busca en youtuve",
            "volumen",
            "abres spotify"
        ]
        
        print("游댢 DEMO: Sistema de Correcci칩n Autom치tica Integrado")
        print("=" * 60)
        
        for command in test_commands:
            print(f"\n游닇 Comando original: '{command}'")
            suggestions = detector.get_correction_suggestions(command)
            
            if suggestions:
                print("游눠 Sugerencias de correcci칩n:")
                for i, suggestion in enumerate(suggestions, 1):
                    print(f"  {i}. {suggestion['corrected']}")
                    print(f"     Tipo: {suggestion['type']} | Confianza: {suggestion['confidence']:.2f}")
                    print(f"     {suggestion['explanation']}")
                
                # Probar an치lisis con correcci칩n autom치tica
                result = detector.analyze_command(command)
                print(f"游늵 Resultado con correcci칩n: {result.command_type} - {result.action}")
            else:
                print("   九 No se detectaron errores")
        
        # Mostrar estad칤sticas
        stats = detector.get_correction_stats()
        print(f"\n游늵 Estad칤sticas de correcci칩n: {stats}")
    else:
        test_detector()
